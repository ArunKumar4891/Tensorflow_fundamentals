{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6230c9d",
   "metadata": {},
   "source": [
    "# Introduction to Regression with neural networks in tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f18ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a722bf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ab07f4efa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating data to view and fit\n",
    "\n",
    "\n",
    "# create the features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "\n",
    "# create labels\n",
    "Y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "\n",
    "# visualize \n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a2480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2820857a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y == X+10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07e76a",
   "metadata": {},
   "source": [
    "##  input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087cfaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create  a demo tensor for our housing price prdection problem\n",
    "\n",
    "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5381903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82526fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.0, 6.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c6a2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X.shape\n",
    "output_shape = Y.shape\n",
    "\n",
    "input_shape , output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839c05fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = Y[0].shape\n",
    "\n",
    "input_shape , output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f355ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6bbfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn our numpy arrays into tensors with dtype float 32\n",
    "\n",
    "\n",
    "\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "Y = tf.cast(tf.constant(Y), dtype=tf.float32)\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b326ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = Y[0].shape\n",
    "\n",
    "input_shape , output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d04ae05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ab086e0a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdbad12",
   "metadata": {},
   "source": [
    "## steps in modelling with tensorflow\n",
    "\n",
    "\n",
    "###  1. creating a model- define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "\n",
    "### 2. compling a model - define the loss function and the optimizer and evaluation metrics\n",
    "\n",
    "### 3. Fitting a model - letting the model try to find patters between X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e832865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 673us/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0887dcd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "#  1. create a model using the sequential API\n",
    "\n",
    "model = tf.keras.Sequential ([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. Compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])\n",
    "\n",
    "\n",
    "\n",
    "# 3. Fit the model\n",
    "\n",
    "model.fit(X, Y, epochs =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d75f4395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out X and Y\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a960da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try and make a prediction using our model\n",
    "\n",
    "y_pred=  model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a9f26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.71602]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056263a",
   "metadata": {},
   "source": [
    "## improving our model\n",
    "\n",
    "\n",
    "\n",
    "### we can improve our model, by alerting the steps we took to create a model.\n",
    "\n",
    "\n",
    "#### 1. Creating a model =  we might add more layers, increase the number of hidden units within eacj of the hidden layers, change the activation function of each layers.\n",
    "\n",
    "\n",
    "#### 2. Compiling the model = here we might change the optimization function or perhaps the 'learning rate' of the optimization function.\n",
    "\n",
    "#### 3. fitting the model = here we might fit a model for more 'epochs' or on more data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6f9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1995b42a",
   "metadata": {},
   "source": [
    "# common ways to improve the model.\n",
    "\n",
    "\n",
    "## 1. Adding layers\n",
    "## 2. increase the number of hidden layers\n",
    "## 3. change the activation functions\n",
    "## 4. change the optimization function\n",
    "## 5. change the learning rate\n",
    "## 6. fitting the more data\n",
    "## 7. fitting for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a87bd497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 837us/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 346us/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 715us/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 707us/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 950us/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 963us/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 798us/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 990us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 969us/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 933us/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 986us/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab08c20a30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model .. model 2\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model =  tf.keras.Sequential ([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2.  compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics = ['mae'])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ca7f779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remind ourselves of the data\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca92498c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the models prediction  has improved...\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dac02b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5736 - mae: 10.5736\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5691 - mae: 10.5691\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5646 - mae: 10.5646\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 10.5601 - mae: 10.5601\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.5511 - mae: 10.5511\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.5466 - mae: 10.5466\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.5421 - mae: 10.5421\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.5376 - mae: 10.5376\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5331 - mae: 10.5331\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5286 - mae: 10.5286\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 10.5241 - mae: 10.5241\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.5196 - mae: 10.5196\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5151 - mae: 10.5151\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 958us/step - loss: 10.5106 - mae: 10.5106\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5061 - mae: 10.5061\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.5016 - mae: 10.5016\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4971 - mae: 10.4971\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4926 - mae: 10.4926\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4881 - mae: 10.4881\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.4836 - mae: 10.4836\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4791 - mae: 10.4791\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4746 - mae: 10.4746\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.4701 - mae: 10.4701\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 760us/step - loss: 10.4656 - mae: 10.4656\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4611 - mae: 10.4611\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4566 - mae: 10.4566\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4521 - mae: 10.4521\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4476 - mae: 10.4476\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4431 - mae: 10.4431\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.4386 - mae: 10.4386\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4341 - mae: 10.4341\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 930us/step - loss: 10.4296 - mae: 10.4296\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4251 - mae: 10.4251\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4206 - mae: 10.4206\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.4161 - mae: 10.4161\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 10.4116 - mae: 10.4116\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4071 - mae: 10.4071\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4026 - mae: 10.4026\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3981 - mae: 10.3981\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3936 - mae: 10.3936\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3891 - mae: 10.3891\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3846 - mae: 10.3846\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 786us/step - loss: 10.3801 - mae: 10.3801\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3756 - mae: 10.3756\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.3711 - mae: 10.3711\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 10.3666 - mae: 10.3666\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3621 - mae: 10.3621\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3576 - mae: 10.3576\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 973us/step - loss: 10.3531 - mae: 10.3531\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3486 - mae: 10.3486\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3441 - mae: 10.3441\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.3396 - mae: 10.3396\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.3351 - mae: 10.3351\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3306 - mae: 10.3306\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 951us/step - loss: 10.3261 - mae: 10.3261\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.3216 - mae: 10.3216\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3171 - mae: 10.3171\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3126 - mae: 10.3126\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3081 - mae: 10.3081\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3036 - mae: 10.3036\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.2991 - mae: 10.2991\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 10.2946 - mae: 10.2946\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2901 - mae: 10.2901\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.2856 - mae: 10.2856\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 10.2811 - mae: 10.2811\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2766 - mae: 10.2766\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2721 - mae: 10.2721\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.2676 - mae: 10.2676\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 579us/step - loss: 10.2631 - mae: 10.2631\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 802us/step - loss: 10.2586 - mae: 10.2586\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2541 - mae: 10.2541\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.2496 - mae: 10.2496\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.2451 - mae: 10.2451\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2406 - mae: 10.2406\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 937us/step - loss: 10.2361 - mae: 10.2361\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2316 - mae: 10.2316\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2271 - mae: 10.2271\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.2226 - mae: 10.2226\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 974us/step - loss: 10.2181 - mae: 10.2181\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2136 - mae: 10.2136\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2091 - mae: 10.2091\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2046 - mae: 10.2046\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.2001 - mae: 10.2001\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1956 - mae: 10.1956\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1911 - mae: 10.1911\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1866 - mae: 10.1866\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1821 - mae: 10.1821\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1776 - mae: 10.1776\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1731 - mae: 10.1731\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1686 - mae: 10.1686\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1641 - mae: 10.1641\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.1596 - mae: 10.1596\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.1551 - mae: 10.1551\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1506 - mae: 10.1506\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1461 - mae: 10.1461\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1416 - mae: 10.1416\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.1371 - mae: 10.1371\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 10.1326 - mae: 10.1326\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.1281 - mae: 10.1281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab09dda340>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again by changing the optimizers.. model 3\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model.\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.Adam(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac9edcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.014063]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the models prediction  has improved...\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17891165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.0407 - mae: 14.0407\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 13.4800 - mae: 13.4800\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 12.9217 - mae: 12.9217\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 12.3612 - mae: 12.3612\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.7937 - mae: 11.7937\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 915us/step - loss: 11.2106 - mae: 11.2106\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.6209 - mae: 10.6209\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.0058 - mae: 10.0058\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3625 - mae: 9.3625\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.6887 - mae: 8.6887\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9730 - mae: 7.9730\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2130 - mae: 7.2130\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 964us/step - loss: 6.3984 - mae: 6.3984\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5215 - mae: 5.5215\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5762 - mae: 4.5762\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0920 - mae: 4.0920\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0292 - mae: 4.0292\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9887 - mae: 3.9887\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.9591 - mae: 3.9591\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8951 - mae: 3.8951\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 970us/step - loss: 3.9391 - mae: 3.9391\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8718 - mae: 3.8718\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.9498 - mae: 3.9498\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8853 - mae: 3.8853\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9245 - mae: 3.9245\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 951us/step - loss: 3.8929 - mae: 3.8929\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8991 - mae: 3.8991\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 612us/step - loss: 3.9005 - mae: 3.9005\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8734 - mae: 3.8734\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9084 - mae: 3.9084\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8507 - mae: 3.8507\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9226 - mae: 3.9226\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8550 - mae: 3.8550\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9021 - mae: 3.9021\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8628 - mae: 3.8628\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8763 - mae: 3.8763\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8707 - mae: 3.8707\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8504 - mae: 3.8504\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8787 - mae: 3.8787\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8298 - mae: 3.8298\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8932 - mae: 3.8932\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8259 - mae: 3.8259\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8783 - mae: 3.8783\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8339 - mae: 3.8339\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8523 - mae: 3.8523\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8420 - mae: 3.8420\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 966us/step - loss: 3.8262 - mae: 3.8262\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8517 - mae: 3.8517\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8055 - mae: 3.8055\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 970us/step - loss: 3.8648 - mae: 3.8648\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7979 - mae: 3.7979\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8533 - mae: 3.8533\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8061 - mae: 3.8061\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 3.8270 - mae: 3.8270\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 944us/step - loss: 3.8144 - mae: 3.8144\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8006 - mae: 3.8006\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8264 - mae: 3.8264\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 964us/step - loss: 3.7796 - mae: 3.7796\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8376 - mae: 3.8376\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7710 - mae: 3.7710\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 960us/step - loss: 3.8270 - mae: 3.8270\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 947us/step - loss: 3.7794 - mae: 3.7794\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8004 - mae: 3.8004\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7879 - mae: 3.7879\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7737 - mae: 3.7737\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 922us/step - loss: 3.8027 - mae: 3.8027\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7524 - mae: 3.7524\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8114 - mae: 3.8114\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7451 - mae: 3.7451\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7994 - mae: 3.7994\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7537 - mae: 3.7537\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7726 - mae: 3.7726\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7624 - mae: 3.7624\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7474 - mae: 3.7474\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7774 - mae: 3.7774\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7238 - mae: 3.7238\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7863 - mae: 3.7863\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7203 - mae: 3.7203\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7705 - mae: 3.7705\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7290 - mae: 3.7290\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7433 - mae: 3.7433\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7379 - mae: 3.7379\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 925us/step - loss: 3.7196 - mae: 3.7196\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7531 - mae: 3.7531\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6939 - mae: 3.6939\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7622 - mae: 3.7622\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6964 - mae: 3.6964\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7403 - mae: 3.7403\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7054 - mae: 3.7054\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7128 - mae: 3.7128\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7145 - mae: 3.7145\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.6903 - mae: 3.6903\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7299 - mae: 3.7299\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.6645 - mae: 3.6645\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 971us/step - loss: 3.7364 - mae: 3.7364\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6735 - mae: 3.6735\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7087 - mae: 3.7087\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.6827 - mae: 3.6827\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6808 - mae: 3.6808\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.6927 - mae: 3.6927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0a1f3550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again by adding 1 dense layer and activation.. model 4\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b63f9c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.727648]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the models prediction  has improved...\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18ea7095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.5267 - mae: 13.5267\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.4372 - mae: 13.4372\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 13.3477 - mae: 13.3477\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 13.2581 - mae: 13.2581\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.1685 - mae: 13.1685\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 13.0788 - mae: 13.0788\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 12.9891 - mae: 12.9891\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.8994 - mae: 12.8994\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 954us/step - loss: 12.8098 - mae: 12.8098\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7209 - mae: 12.7209\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6318 - mae: 12.6318\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 964us/step - loss: 12.5427 - mae: 12.5427\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.4536 - mae: 12.4536\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.3643 - mae: 12.3643\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2750 - mae: 12.2750\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 12.1855 - mae: 12.1855\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 12.0960 - mae: 12.0960\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 12.0062 - mae: 12.0062\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.9162 - mae: 11.9162\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.8261 - mae: 11.8261\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.7360 - mae: 11.7360\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.6460 - mae: 11.6460\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.5558 - mae: 11.5558\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.4656 - mae: 11.4656\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.3752 - mae: 11.3752\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.2845 - mae: 11.2845\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.1935 - mae: 11.1935\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.1023 - mae: 11.1023\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.0108 - mae: 11.0108\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9190 - mae: 10.9190\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.8269 - mae: 10.8269\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.7346 - mae: 10.7346\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6419 - mae: 10.6419\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.5489 - mae: 10.5489\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.4657 - mae: 10.4657\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3975 - mae: 10.3975\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.3287 - mae: 10.3287\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.2594 - mae: 10.2594\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1896 - mae: 10.1896\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.1194 - mae: 10.1194\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.0486 - mae: 10.0486\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.9775 - mae: 9.9775\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9060 - mae: 9.9060\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8343 - mae: 9.8343\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7621 - mae: 9.7621\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.6895 - mae: 9.6895\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.6164 - mae: 9.6164\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5427 - mae: 9.5427\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.4686 - mae: 9.4686\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3940 - mae: 9.3940\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.3189 - mae: 9.3189\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1673 - mae: 9.1673\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.0908 - mae: 9.0908\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0138 - mae: 9.0138\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.9363 - mae: 8.9363\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8583 - mae: 8.8583\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7799 - mae: 8.7799\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7010 - mae: 8.7010\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.6218 - mae: 8.6218\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.5422 - mae: 8.5422\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.4622 - mae: 8.4622\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3815 - mae: 8.3815\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3003 - mae: 8.3003\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2185 - mae: 8.2185\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.1362 - mae: 8.1362\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.0533 - mae: 8.0533\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.9698 - mae: 7.9698\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.8858 - mae: 7.8858\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.8012 - mae: 7.8012\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.7161 - mae: 7.7161\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 872us/step - loss: 7.6304 - mae: 7.6304\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.5441 - mae: 7.5441\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 875us/step - loss: 7.4573 - mae: 7.4573\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.3700 - mae: 7.3700\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 990us/step - loss: 7.2822 - mae: 7.2822\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1937 - mae: 7.1937\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.1046 - mae: 7.1046\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0148 - mae: 7.0148\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9244 - mae: 6.9244\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.8333 - mae: 6.8333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 6.7416 - mae: 6.7416\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6493 - mae: 6.6493\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.5563 - mae: 6.5563\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 968us/step - loss: 6.4626 - mae: 6.4626\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 864us/step - loss: 6.3684 - mae: 6.3684\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 533us/step - loss: 6.2735 - mae: 6.2735\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1779 - mae: 6.1779\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.0816 - mae: 6.0816\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 963us/step - loss: 5.9845 - mae: 5.9845\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8868 - mae: 5.8868\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.7883 - mae: 5.7883\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6890 - mae: 5.6890\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5890 - mae: 5.5890\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4883 - mae: 5.4883\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.3869 - mae: 5.3869\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 990us/step - loss: 5.2848 - mae: 5.2848\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.1819 - mae: 5.1819\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.0783 - mae: 5.0783\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.9739 - mae: 4.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0a45d340>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again by adding 1 dense layer and activation and changing the optimizers.. model 5\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.Adam(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29c6cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB09DD7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25.852005]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the models prediction  has improved...\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9af2a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 937us/step - loss: 12.5326 - mae: 12.5326\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.8956 - mae: 11.8956\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 11.2464 - mae: 11.2464\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5791 - mae: 10.5791\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 570us/step - loss: 9.8874 - mae: 9.8874\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.1649 - mae: 9.1649\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4050 - mae: 8.4050\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.6117 - mae: 7.6117\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 952us/step - loss: 6.7798 - mae: 6.7798\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8888 - mae: 5.8888\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9302 - mae: 4.9302\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1685 - mae: 4.1685\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0209 - mae: 4.0209\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 849us/step - loss: 3.9298 - mae: 3.9298\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9596 - mae: 3.9596\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 837us/step - loss: 3.9400 - mae: 3.9400\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9405 - mae: 3.9405\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 950us/step - loss: 3.9523 - mae: 3.9523\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 972us/step - loss: 3.9142 - mae: 3.9142\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9599 - mae: 3.9599\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8896 - mae: 3.8896\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.9648 - mae: 3.9648\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8971 - mae: 3.8971\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 3.9391 - mae: 3.9391\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.9123 - mae: 3.9123\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9192 - mae: 3.9192\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9199 - mae: 3.9199\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8926 - mae: 3.8926\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9277 - mae: 3.9277\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8659 - mae: 3.8659\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 720us/step - loss: 3.9356 - mae: 3.9356\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8655 - mae: 3.8655\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9214 - mae: 3.9214\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8808 - mae: 3.8808\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8966 - mae: 3.8966\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8887 - mae: 3.8887\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8697 - mae: 3.8697\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 3.8967 - mae: 3.8967\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 924us/step - loss: 3.8428 - mae: 3.8428\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9048 - mae: 3.9048\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8370 - mae: 3.8370\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8996 - mae: 3.8996\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 697us/step - loss: 3.8505 - mae: 3.8505\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8727 - mae: 3.8727\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8586 - mae: 3.8586\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8456 - mae: 3.8456\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 910us/step - loss: 3.8668 - mae: 3.8668\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8184 - mae: 3.8184\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8751 - mae: 3.8751\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8119 - mae: 3.8119\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 952us/step - loss: 3.8747 - mae: 3.8747\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8214 - mae: 3.8214\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8475 - mae: 3.8475\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8296 - mae: 3.8296\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 939us/step - loss: 3.8202 - mae: 3.8202\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.8380 - mae: 3.8380\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7926 - mae: 3.7926\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8494 - mae: 3.8494\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7849 - mae: 3.7849\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8486 - mae: 3.8486\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7933 - mae: 3.7933\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8211 - mae: 3.8211\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8017 - mae: 3.8017\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7934 - mae: 3.7934\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.8103 - mae: 3.8103\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7656 - mae: 3.7656\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8265 - mae: 3.8265\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7577 - mae: 3.7577\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8211 - mae: 3.8211\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7662 - mae: 3.7662\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7933 - mae: 3.7933\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7749 - mae: 3.7749\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 975us/step - loss: 3.7654 - mae: 3.7654\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7837 - mae: 3.7837\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7411 - mae: 3.7411\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8001 - mae: 3.8001\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7315 - mae: 3.7315\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.7923 - mae: 3.7923\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7402 - mae: 3.7402\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7642 - mae: 3.7642\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7491 - mae: 3.7491\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7359 - mae: 3.7359\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7583 - mae: 3.7583\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 913us/step - loss: 3.7143 - mae: 3.7143\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7746 - mae: 3.7746\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 770us/step - loss: 3.7063 - mae: 3.7063\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7622 - mae: 3.7622\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.7152 - mae: 3.7152\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7338 - mae: 3.7338\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7243 - mae: 3.7243\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7052 - mae: 3.7052\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.7373 - mae: 3.7373\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6832 - mae: 3.6832\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7502 - mae: 3.7502\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6821 - mae: 3.6821\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 983us/step - loss: 3.7308 - mae: 3.7308\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6912 - mae: 3.6912\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7020 - mae: 3.7020\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 857us/step - loss: 3.7005 - mae: 3.7005\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 910us/step - loss: 3.6736 - mae: 3.6736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0a1dea90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again ... model 7\n",
    "\n",
    "\n",
    "# 1. Create the model by adding 100 hidden layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78627010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0A0601F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.787724]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets the predict the model\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd0fa410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.2349 - mae: 13.2349\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 952us/step - loss: 12.9286 - mae: 12.9286\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 12.6250 - mae: 12.6250\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 694us/step - loss: 12.3289 - mae: 12.3289\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 955us/step - loss: 12.0368 - mae: 12.0368\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.7446 - mae: 11.7446\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 972us/step - loss: 11.4516 - mae: 11.4516\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.1640 - mae: 11.1640\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 807us/step - loss: 10.8873 - mae: 10.8873\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.6615 - mae: 10.6615\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 10.4616 - mae: 10.4616\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 970us/step - loss: 10.2592 - mae: 10.2592\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.0535 - mae: 10.0535\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.8434 - mae: 9.8434\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6298 - mae: 9.6298\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.4143 - mae: 9.4143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1988 - mae: 9.1988\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 964us/step - loss: 8.9780 - mae: 8.9780\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.7522 - mae: 8.7522\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 844us/step - loss: 8.5204 - mae: 8.5204\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.2825 - mae: 8.2825\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0384 - mae: 8.0384\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.7881 - mae: 7.7881\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5313 - mae: 7.5313\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2702 - mae: 7.2702\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.0071 - mae: 7.0071\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7435 - mae: 6.7435\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4785 - mae: 6.4785\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.2118 - mae: 6.2118\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.9397 - mae: 5.9397\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.6595 - mae: 5.6595\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.3697 - mae: 5.3697\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.0704 - mae: 5.0704\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.7622 - mae: 4.7622\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4443 - mae: 4.4443\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 4.1426 - mae: 4.1426\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 411us/step - loss: 4.0398 - mae: 4.0398\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 431us/step - loss: 3.9395 - mae: 3.9395\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 871us/step - loss: 3.8477 - mae: 3.8477\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9020 - mae: 3.9020\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 941us/step - loss: 3.9484 - mae: 3.9484\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9871 - mae: 3.9871\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0191 - mae: 4.0191\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0450 - mae: 4.0450\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 4.0648 - mae: 4.0648\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0788 - mae: 4.0788\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0875 - mae: 4.0875\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0915 - mae: 4.0915\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0912 - mae: 4.0912\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0870 - mae: 4.0870\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0787 - mae: 4.0787\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.0674 - mae: 4.0674\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0527 - mae: 4.0527\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0353 - mae: 4.0353\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0223 - mae: 4.0223\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.0017 - mae: 4.0017\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 957us/step - loss: 3.9796 - mae: 3.9796\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9599 - mae: 3.9599\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.9378 - mae: 3.9378\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9134 - mae: 3.9134\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 963us/step - loss: 3.8871 - mae: 3.8871\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8591 - mae: 3.8591\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8299 - mae: 3.8299\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.7996 - mae: 3.7996\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.7685 - mae: 3.7685\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 965us/step - loss: 3.7364 - mae: 3.7364\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 980us/step - loss: 3.7033 - mae: 3.7033\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.6692 - mae: 3.6692\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6705 - mae: 3.6705\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 984us/step - loss: 3.6871 - mae: 3.6871\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6986 - mae: 3.6986\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6984 - mae: 3.6984\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.6906 - mae: 3.6906\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6751 - mae: 3.6751\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6527 - mae: 3.6527\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6268 - mae: 3.6268\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.5933 - mae: 3.5933\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6016 - mae: 3.6016\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6094 - mae: 3.6094\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.6101 - mae: 3.6101\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.6090 - mae: 3.6090\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.6006 - mae: 3.6006\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 808us/step - loss: 3.5871 - mae: 3.5871\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.5716 - mae: 3.5716\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.5552 - mae: 3.5552\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5383 - mae: 3.5383\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5143 - mae: 3.5143\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5052 - mae: 3.5052\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5086 - mae: 3.5086\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5013 - mae: 3.5013\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.4837 - mae: 3.4837\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.4607 - mae: 3.4607\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4549 - mae: 3.4549\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4435 - mae: 3.4435\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 968us/step - loss: 3.4291 - mae: 3.4291\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.4103 - mae: 3.4103\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 747us/step - loss: 3.4080 - mae: 3.4080\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.3953 - mae: 3.3953\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 961us/step - loss: 3.3766 - mae: 3.3766\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.3672 - mae: 3.3672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0b7c6ee0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again by adding 1 dense layer and activation and changing the optimizers.. model 5\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(100, activation ='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.Adam(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f78e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0BA2D3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.557589]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets the predict the model\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c898a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.1610 - mae: 13.1610\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.3268 - mae: 7.3268\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.2921 - mae: 11.2921\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.6322 - mae: 8.6322\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5406 - mae: 7.5406\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0975 - mae: 8.0975\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9990 - mae: 6.9990\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2742 - mae: 6.2742\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.7146 - mae: 6.7146\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2922 - mae: 6.2922\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6885 - mae: 5.6885\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 936us/step - loss: 5.3562 - mae: 5.3562\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 5.2692 - mae: 5.2692\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.7190 - mae: 4.7190\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5466 - mae: 4.5466\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2562 - mae: 4.2562\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 3.7022 - mae: 3.7022\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.0912 - mae: 3.0912\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.9849 - mae: 2.9849\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.9496 - mae: 1.9496\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.1419 - mae: 2.1419\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6728 - mae: 1.6728\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.7101 - mae: 0.7101\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5108 - mae: 1.5108\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 525us/step - loss: 1.4011 - mae: 1.4011\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1330 - mae: 2.1330\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 420us/step - loss: 1.6891 - mae: 1.6891\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1288 - mae: 1.1288\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 925us/step - loss: 0.8225 - mae: 0.8225\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4462 - mae: 0.4462\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4901 - mae: 0.4901\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0500 - mae: 1.0500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.8437 - mae: 0.8437\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1891 - mae: 1.1891\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1426 - mae: 1.1426\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.3529 - mae: 0.3529\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 945us/step - loss: 0.1845 - mae: 0.1845\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 893us/step - loss: 0.8532 - mae: 0.8532\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.9641 - mae: 0.9641\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4705 - mae: 0.4705\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4808 - mae: 0.4808\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4141 - mae: 0.4141\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1486 - mae: 0.1486\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8893 - mae: 0.8893\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8310 - mae: 0.8310\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2519 - mae: 0.2519\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3145 - mae: 0.3145\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 954us/step - loss: 0.5251 - mae: 0.5251\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3833 - mae: 0.3833\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.8564 - mae: 0.8564\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.9077 - mae: 0.9077\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 929us/step - loss: 0.0579 - mae: 0.0579\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.3909 - mae: 1.3909\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8703 - mae: 1.8703\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.5986 - mae: 1.5986\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8615 - mae: 0.8615\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1870 - mae: 1.1870\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 754us/step - loss: 1.6724 - mae: 1.6724\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2121 - mae: 1.2121\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0586 - mae: 0.0586\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.3394 - mae: 0.3394\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4597 - mae: 0.4597\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3097 - mae: 0.3097\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6216 - mae: 0.6216\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5213 - mae: 0.5213\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4003 - mae: 0.4003\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4028 - mae: 0.4028\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 961us/step - loss: 0.4292 - mae: 0.4292\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3257 - mae: 0.3257\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5066 - mae: 0.5066\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5012 - mae: 0.5012\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2720 - mae: 0.2720\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1040 - mae: 0.1040\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8149 - mae: 0.8149\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8452 - mae: 0.8452\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 980us/step - loss: 0.2121 - mae: 0.2121\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 949us/step - loss: 1.0112 - mae: 1.0112\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2736 - mae: 1.2736\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8216 - mae: 0.8216\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3501 - mae: 0.3501\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6552 - mae: 0.6552\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.9053 - mae: 0.9053\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1759 - mae: 1.1759\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8193 - mae: 0.8193\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2935 - mae: 0.2935\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5845 - mae: 0.5845\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1867 - mae: 0.1867\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8779 - mae: 0.8779\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1496 - mae: 1.1496\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7783 - mae: 0.7783\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4109 - mae: 0.4109\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6329 - mae: 0.6329\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 325us/step - loss: 0.2283 - mae: 0.2283\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8249 - mae: 0.8249\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0963 - mae: 1.0963\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7553 - mae: 0.7553\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2306 - mae: 0.2306\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4262 - mae: 0.4262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0ba49280>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again by adding 1 dense layer and activation and changing the optimizers and adding LR.. model 5\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = None),\n",
    "    tf.keras.layers.Dense(100, activation =None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fa5e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0BC018B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.755377]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets the predict the model\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f674f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.2826 - mae: 14.2826\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2700 - mae: 13.2700\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2644 - mae: 12.2644\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2645 - mae: 11.2645\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.2666 - mae: 10.2666\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.2641 - mae: 9.2641\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.2484 - mae: 8.2484\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2108 - mae: 7.2108\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.6753 - mae: 6.6753\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1916 - mae: 7.1916\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.8009 - mae: 7.8009\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.0781 - mae: 8.0781\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0273 - mae: 8.0273\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.7406 - mae: 7.7406\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2835 - mae: 7.2835\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 885us/step - loss: 6.7627 - mae: 6.7627\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 6.3882 - mae: 6.3882\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0027 - mae: 6.0027\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 950us/step - loss: 5.9548 - mae: 5.9548\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1917 - mae: 6.1917\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3561 - mae: 6.3561\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3743 - mae: 6.3743\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.2671 - mae: 6.2671\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.0497 - mae: 6.0497\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7326 - mae: 5.7326\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3232 - mae: 5.3232\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1073 - mae: 5.1073\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.0674 - mae: 5.0674\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1071 - mae: 5.1071\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.0859 - mae: 5.0859\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.0074 - mae: 5.0074\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.8752 - mae: 4.8752\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6926 - mae: 4.6926\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4628 - mae: 4.4628\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.1886 - mae: 4.1886\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8724 - mae: 3.8724\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 962us/step - loss: 3.6457 - mae: 3.6457\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.5805 - mae: 3.5805\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5018 - mae: 3.5018\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2569 - mae: 3.2569\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.8551 - mae: 2.8551\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 959us/step - loss: 2.6160 - mae: 2.6160\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.5078 - mae: 2.5078\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3407 - mae: 2.3407\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.0204 - mae: 2.0204\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 969us/step - loss: 1.5983 - mae: 1.5983\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.4027 - mae: 1.4027\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2506 - mae: 1.2506\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8901 - mae: 0.8901\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.3310 - mae: 0.3310\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6027 - mae: 0.6027\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 908us/step - loss: 0.7892 - mae: 0.7892\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8675 - mae: 0.8675\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7519 - mae: 0.7519\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9684 - mae: 0.9684\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.9553 - mae: 0.9553\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.8661 - mae: 0.8661\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8665 - mae: 0.8665\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6898 - mae: 0.6898\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5725 - mae: 0.5725\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3942 - mae: 0.3942\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1883 - mae: 0.1883\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1035 - mae: 0.1035\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2355 - mae: 0.2355\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3359 - mae: 0.3359\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3707 - mae: 0.3707\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3669 - mae: 0.3669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3916 - mae: 0.3916\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2608 - mae: 0.2608\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2211 - mae: 0.2211\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.0403 - mae: 0.0403\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1908 - mae: 0.1908\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2450 - mae: 0.2450\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2901 - mae: 0.2901\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3399 - mae: 0.3399\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2446 - mae: 0.2446\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 926us/step - loss: 0.1675 - mae: 0.1675\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0553 - mae: 0.0553\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1708 - mae: 0.1708\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2479 - mae: 0.2479\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2707 - mae: 0.2707\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 931us/step - loss: 0.3435 - mae: 0.3435\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3172 - mae: 0.3172\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2501 - mae: 0.2501\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 848us/step - loss: 0.2232 - mae: 0.2232\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0593 - mae: 0.0593\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1324 - mae: 0.1324\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1733 - mae: 0.1733\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1534 - mae: 0.1534\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1481 - mae: 0.1481\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0385 - mae: 0.0385\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2255 - mae: 0.2255\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1460 - mae: 0.1460\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3028 - mae: 0.3028\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2921 - mae: 0.2921\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0961 - mae: 0.0961\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4288 - mae: 0.4288\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4565 - mae: 0.4565\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2418 - mae: 0.2418\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 971us/step - loss: 0.4860 - mae: 0.4860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0ccfaf10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuild our model again by adding 1 dense layer and activation and changing the optimizers.. model 5\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = None),\n",
    "    #tf.keras.layers.Dense(100, activation =None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, Y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a9c29fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0CDB9CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25.418127]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets the predict the model\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad52e1f",
   "metadata": {},
   "source": [
    "## evaluating the model\n",
    "\n",
    "\n",
    "#### in practice, a typical workflow you'll go through when building NN is:\n",
    "\n",
    "\n",
    "####  build a model --> fit it -->  evaluate it -->  tweak the model --> fit it -->  evaluate it --> tweak a model --> fit it -->  evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c0a58",
   "metadata": {},
   "source": [
    "#####  when comes to evaluation,... there is an important words you should memorize ----   VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24c3f600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a bigger dataset\n",
    "\n",
    "\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aafd493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make labels for the dataset\n",
    "\n",
    "Y = X +10\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28767b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ab0d03d1c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87a1fd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ab0d063100>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkrElEQVR4nO3deXhU9dn/8ffNvu9bWELY1yBCAHFXqCIVEVzqUqXFirb1170QBCvuYLXWtloffNRHW6u2BBAVFXFfUAGLSVgCYQ+EfQtL9vv3R8ZekYZ1JjmTyed1XVw58z0z59x8Z+aTk3Mmd8zdERGR2FQt6AJERKT8KORFRGKYQl5EJIYp5EVEYphCXkQkhtUIuoDSWrRo4QkJCUGXISJSqSxdunSXu7csa11UhXxCQgJLliwJugwRkUrFzDYea51O14iIxDCFvIhIDFPIi4jEMIW8iEgMU8iLiMQwhbyISAxTyIuIxDCFvIhIgNydVxZvYuGK7eWy/aj6ZSgRkapk0+7DJM9O5bO1u7m8XxzDe7eO+D4U8iIiFayo2Hnu0/U8siCDGtWq8cCYvlw/KL5c9qWQFxGpQBnbcpiUksqyzfu4uGcrHhjTl7jGdcttfyd9Tt7MnjWzHWaWXmqsmZm9Y2ZrQl+bllo32cwyzSzDzC6NdOEiIpVJfmExf1y4msv//DGb9hzm8ev688y4pHINeDi1C6//B4w4aiwZeNfduwHvhm5jZr2B64A+occ8aWbVw65WRKQS+nrzPkb9+RP+uHANI/rG8c4vz2d0/3aYWbnv+6RP17j7R2aWcNTwaODC0PLzwAfApND4y+6eB6w3s0xgMLAozHpFRCqNI/lF/OGdDJ75ZD2tGtbhf29OKpeLq8cT7jn51u6eDeDu2WbWKjTeDvi81P2yQmP/xcwmABMA4uPL58KDiEhFW7R2N8mzU9m4+zA3DIkn+bKeNKpTs8LrKK8Lr2X9DOJl3dHdZwIzAZKSksq8j4hIZXEgt4CH5q/ipS830bF5Pf5x6xDO7tIisHrCDfntZhYXOoqPA3aExrOADqXu1x7YGua+RESi2rsrtzNlTjo7cnKZcH5nfjm8O3VrBXs5MtzfeJ0HjAstjwNeLTV+nZnVNrNOQDfgyzD3JSISlXYfzONnL/2bW55fQpN6NZnzk3O4c2SvwAMeTuFI3sxeouQiawszywLuBqYD/zSzW4BNwDUA7r7czP4JrAAKgZ+6e1GEaxcRCZS7M+/rrdzz2gpycgv45fDu/PjCLtSqET0dY07l0zXXH2PVsGPc/wHggdMpSkQk2mXvP8LUOem8u2oH/Ts04eGr+9G9dcOgy/ov+o1XEZFTUFzsvLx4Mw/NX0lBcTFTv9uLH57TierVyv8z76dDIS8icpI27DpE8uxUPl+3h7O7NGf62H7EN68XdFnHpZAXETmBwqJinv10PY8uWE2tGtWYcVUi1yZ1qJDfWA2XQl5E5DhWbTvAxFmppGbt5zu9W3P/lX1p3ahO0GWdNIW8iEgZ8gqLeOL9tTz5fiaN69bkLzecyXcT4yrF0XtpCnkRkaN8tWkvk2alsmbHQcac2Y7fXd6bpvVrBV3WaVHIi4iEHM4v5NEFq3n20/W0aVSH534wiIt6tjrxA6OYQl5EBPg0cxfJs1PZvOcIN53VkYkjetAwgIZikaaQF5Eqbf+RAh6av5KXF2+mU4v6vDLhLIZ0bh50WRGjkBeRKmvB8m1MnZvO7kP53H5BF34xvBt1agbfbyaSFPIiUuXsOpjHtHnLeT01m15xjXhm3CAS2zcOuqxyoZAXkSrD3Zm7bAv3vLaCw3lF/OaS7tx2QRdqVo+ehmKRppAXkSph674jTJmTxvsZOxkQX9JQrGur6GsoFmkKeRGJacXFzotfbmLGm6soKnbuHtWbm4cmRG1DsUhTyItIzFq/6xCTUlL5cv0ezu3agofGJtKhWXQ3FIs0hbyIxJzComL+95P1PPbOamrXqMbDV/fjmoHtK11LgkgIO+TNrAfwSqmhzsDvgCbArcDO0Pid7j4/3P2JiBzPiq0HmJjyNelbDnBpn9bcN7ovrSpRQ7FICzvk3T0D6A9gZtWBLcAc4IfAY+7+SLj7EBE5kbzCIv7yXiZ//WAtTerV5IkbBjAysU2VPHovLdKna4YBa919Y1WfWBGpOEs37mHirFTW7jzEVQPaM/W7vSptQ7FIi3TIXwe8VOr2HWZ2M7AE+LW7743w/kSkCjuUV8jv387g+UUbaNu4Ls+PH8wF3VsGXVZUMXePzIbMagFbgT7uvt3MWgO7AAfuA+LcfXwZj5sATACIj48fuHHjxojUIyKx7aPVO5k8O40t+44wbmhHfjuiJw1qV83PkpjZUndPKmtdJGfkMuArd98O8M3XUAFPA6+X9SB3nwnMBEhKSorMdxwRiVn7Dxdw3xsrmLU0i84t6/Ov24cyKKFZ0GVFrUiG/PWUOlVjZnHunh26OQZIj+C+RKQKeis9m7teXc6eQ/n85MIu/GxY7DUUi7SIhLyZ1QO+A9xWavhhM+tPyemaDUetExE5aTtycrn71eW8mb6N3nGNeO4Hg+jbLjYbikVaRELe3Q8DzY8auykS2xaRqsvdSflqC/e9voIjBUVMHNGDW8/rHNMNxSKtal6lEJGol7X3MHfOSeej1TtJ6tiU6Vf1o2urBkGXVeko5EUkqhQXO3/7fCMz3lqFAfeO7sP3h3SkWhVpKBZpCnkRiRprdx5k0qxUlmzcy/ndW/LgmL60b1q1GopFmkJeRAJXUFTMzI/W8fi7a6hbszqPXnMGYwe0q/ItCSJBIS8igUrfsp+Js1JZkX2AkYltmHZFH1o1rLoNxSJNIS8igcgtKOLxd9cw86N1NKtfi6e+P4ARfeOCLivmKORFpMIt3rCHSbNSWbfrENcMbM/U7/amcb2aQZcVkxTyIlJhDuYV8vBbq3hh0UbaN63L324ZzHnd1FCsPCnkRaRCfJCxgylz0tm6/wg/ODuB317ag/pVtKFYRdIMi0i52nson/veWMHsr7bQpWV9Zt0+lIEd1VCsoijkRaRcuDtvpm/jd6+ms+9wAf/v4q7ccXFXatdQQ7GKpJAXkYjbcSCXu15N5+3l20ls15gXxg+hd9tGQZdVJSnkRSRi3J1/Lc3i/tdXkFdYTPJlPfnRuZ2ooYZigVHIi0hEbN5zmMmz0/gkcxeDOzVj+thEOrdUQ7GgKeRFJCxFxc4Lizbw8FsZVK9m3H9lX24YHK+GYlFCIS8ipy1zRw4TZ6Xy1aZ9XNijJQ+OSaRtk7pBlyWlKORF5JQVFBXzPx+u5U/vZlK/dnUe+94ZXNlfDcWiUaT+/N8GIAcoAgrdPcnMmgGvAAmU/Pm/a919byT2JyLBScvaz29nfc2qbTlc3i+OaVf0oUWD2kGXJccQySP5i9x9V6nbycC77j7dzJJDtydFcH8iUoFyC4p4bOFqnv5oHS0a1GbmTQO5pE+boMuSEyjP0zWjgQtDy88DH6CQF6mUvli3m+TZaazfdYjrBnVg8sheNK6rhmKVQaRC3oEFZubA/7j7TKC1u2cDuHu2mbUq64FmNgGYABAfHx+hckQkEnJyC5jx1ir+/vkmOjSry4s/GsI5XVsEXZacgkiF/DnuvjUU5O+Y2aqTfWDoG8JMgKSkJI9QPSISpvdX7eDOOWlsP5DLj87txK8u6U69WvqsRmUTkWfM3beGvu4wsznAYGC7mcWFjuLjgB2R2JeIlK89h/K597XlzF22lW6tGvDkj8/mzPimQZclpynskDez+kA1d88JLV8C3AvMA8YB00NfXw13XyJSftyd11KzuWfecg7kFvDzYd34yUVd1FCskovEkXxrYE7o87E1gH+4+1tmthj4p5ndAmwCronAvkSkHGzbn8vUueksXLmdM9o3ZsbVQ+jZRg3FYkHYIe/u64AzyhjfDQwLd/siUn7cnZcXb+bBN1ZSUFzMlJG9GH9uJ6qrJUHM0FUUkSpq4+5DJKeksWjdbs7q3IzpY/uR0KJ+0GVJhCnkRaqYomLnuU/X88iCDGpWq8ZDYxP5XlIHNRSLUQp5kSokY1sOE1NS+XrzPob1bMX9Y/oS11gNxWKZQl6kCsgvLObJDzJ54v1MGtapyZ+uP5NR/eLUUKwKUMiLxLhlm/cxaVYqGdtzGN2/LXeP6kOz+rWCLksqiEJeJEYdyS/iD+9k8Mwn62nVsA7PjEtiWK/WQZclFUwhLxKDPlu7i+SUNDbtOcz1g+OZPLInjeqooVhVpJAXiSEHcgt4aP4qXvpyEx2b1+OlW89iaJfmQZclAVLIi8SIhSu2M2VuGjtz8phwfmd+Obw7dWupJUFVp5AXqeR2H8zjntdWMO/rrfRs05CZNyVxRocmQZclUUIhL1JJuTvzvt7KtHnLOZhXyC+Hd+fHF3ahVo1qQZcmUUQhL1IJZe8/wtQ56by7agf9OzTh4av70b11w6DLkiikkBepRIqLnZcWb+Kh+asoKnbuurw3Pzg7QQ3F5JgU8iKVxPpdh0hOSeWL9Xs4p2tzHhrTj/jm9YIuS6KcQl4kyhUWFfPsp+t5dMFqatWoxoyrErk2qYNaEshJUciLRLGV2QeYlJJKatZ+vtO7Nfdf2ZfWjeoEXZZUIpH4838dgBeANkAxMNPdHzezacCtwM7QXe909/nh7k+kKsgrLOKJ9zJ58oO1NKlXkyduGMDIxDY6epdTFokj+ULg1+7+lZk1BJaa2TuhdY+5+yMR2IdIlfHVpr1MmpXKmh0HGXtmO+66vDdN1VBMTlMk/vxfNpAdWs4xs5VAu3C3K1LVHM4v5JG3V/PcZ+uJa1SH534wiIt6tgq6LKnkInpO3swSgDOBL4BzgDvM7GZgCSVH+3vLeMwEYAJAfHx8JMsRqTQ+zdxF8uxUNu85wk1ndWTiiB40VEMxiQBz98hsyKwB8CHwgLvPNrPWwC7AgfuAOHcff7xtJCUl+ZIlSyJSj0hlsP9IAQ++sZJXlmymU4v6TB+byJDOaigmp8bMlrp7UlnrInIkb2Y1gRTgRXefDeDu20utfxp4PRL7EokVC5ZvY+rcdHYfyuf2C7rwi+HdqFNTDcUksiLx6RoDngFWuvsfSo3Hhc7XA4wB0sPdl0gs2JmTx7TXlvNGajY92zTkmXGDSGzfOOiyJEZF4kj+HOAmIM3MloXG7gSuN7P+lJyu2QDcFoF9iVRa7s7cZVu457UVHM4r4jeXdOe2C7pQs7oaikn5icSnaz4Byvrwrj4TLxKyZd8RpsxJ44OMnQyIL2ko1rWVGopJ+dNvvIqUo+Ji58UvNjL9zVUUO9w9qjc3D1VDMak4CnmRcrJ250Emp6Tx5YY9nNu1BQ+NTaRDMzUUk4qlkBeJsMKiYmZ+vI4/LlxDnRrVePjqflwzsL1aEkggFPIiEbR8634mpaSSvuUAI/q04d7RfWilhmISIIW8SATkFhTx5/fW8NSH62harxZ/vXEAlyXGBV2WiEJeJFxLNuxhYkoq63Ye4qoB7bnr8l40qaeGYhIdFPIip+lQXiG/fzuD5xdtoG3jurwwfjDnd28ZdFki36KQFzkNH63eyeTZaWzdf4RxQxP47aU9qF9bbyeJPnpVipyCfYfzuf+NlcxamkXnlvX5121DSUpoFnRZIsekkBc5SW+mZXPXq8vZezifn1zYhZ8NU0MxiX4KeZET2JGTy92vLufN9G30aduI58cPok9bNRSTykEhL3IM7s6spVnc/8ZKjhQUMXFED249r7MaikmlopAXKcPmPYeZMjedj1bvZFBCU6Zf1Y8uLRsEXZbIKVPIi5RSXOy8sGgDD7+dgQH3XNGHm87qSDU1FJNKSiEvEpK54yDJKaks2biX87u35MExfWnfVA3FpHJTyEuVV1BUzMyP1vH4wjXUrVWdR685g7ED2qmhmMSEcg95MxsBPA5UB/7X3aeX9z5FTlb6lv1MnJXKiuwDjExswz1X9KVlw9pBlyUSMeUa8mZWHXgC+A6QBSw2s3nuvqI89ytyIrkFRTz+7hpmfrSOZvVr8dT3BzCirxqKSewp7yP5wUCmu68DMLOXgdGAQl4Cs3jDHibNSmXdrkNcm9SeKSN707hezaDLEikX5R3y7YDNpW5nAUNK38HMJgATAOLj48u5HKnKDuYV8vBbq3hh0UbaN63L328ZwrndWgRdlki5Ku+QL+vKlX/rhvtMYCZAUlKSl3F/kbB9kLGDO2enkX0gl/HndOLXl3RXQzGpEsr7VZ4FdCh1uz2wtZz3KfIfew/lc9/rK5j97y10bdWAWbefzcCOTYMuS6TClHfILwa6mVknYAtwHXBDOe9TBHdnfto27p6Xzr7DBfzs4q789OKu1K6hhmJStZRryLt7oZndAbxNyUcon3X35eW5T5EdB3KZOjedBSu2k9iuMS+MH0Lvto2CLkskEOV+UtLd5wPzy3s/Iu7Ov5Zkcd8bK8gvLGbyZT255dxO1FBDManCdOVJYsLmPYeZPDuNTzJ3MbhTM6aPTaSzGoqJKOSlcisqdp7/bAO/fzuD6tWM+6/syw2D49VQTCREIS+V1prtOUxKSeWrTfu4sEdLHhyTSNsmdYMuSySqKOSl0ikoKuapD9by5/cyqV+7On/8Xn9G92+rhmIiZVDIS6WSmrWPibNSWbUth1FntOXuUb1p0UANxUSORSEvlUJuQRGPLVzN0x+to2XD2jx9cxLf6d066LJEop5CXqLe5+t2k5ySyobdh7l+cAeSL+tF47pqKCZyMhTyErVycguY/uYqXvxiE/HN6vHij4ZwTlc1FBM5FQp5iUrvrdrOlDnpbD+Qy4/O7cSvLulOvVp6uYqcKr1rJKrsPpjHva+v4NVlW+neugFP3ng2Z8aroZjI6VLIS1Rwd15LzWbavOXk5Bbw82Hd+OlFXalVQy0JRMKhkJfAbdufy9S5aSxcuYMz2jdmxtVD6NlGDcVEIkEhL4Fxd15evJkH31hJQXExU0b2Yvy5naiulgQiEaOQl0Bs3H2I5JQ0Fq3bzVmdmzF9bD8SWtQPuiyRmKOQlwpVVOw89+l6HlmQQc1q1XhobCLXDeqglgQi5UQhLxUmY1sOE1NS+XrzPob3asX9VybSpnGdoMsSiWlhhbyZ/R4YBeQDa4Efuvs+M0sAVgIZobt+7u63h7MvqbzyC4t58oNMnng/k4Z1avKn689kVL84Hb2LVIBwj+TfASaH/szfDGAyMCm0bq279w9z+1LJLdu8j0mzUsnYnsPo/m25e1QfmtWvFXRZIlVGWCHv7gtK3fwcuDq8ciRWHMkv4g/vZPDMJ+tp1bAOz4xLYlgvNRQTqWiRPCc/Hnil1O1OZvZv4AAw1d0/LutBZjYBmAAQHx8fwXIkKJ+t3UVyShqb9hzmxiHxJF/Wk4Z11FBMJAgnDHkzWwi0KWPVFHd/NXSfKUAh8GJoXTYQ7+67zWwgMNfM+rj7gaM34u4zgZkASUlJfnr/DYkGB3ILeGj+Kl76chMdm9fjpVvPYmiX5kGXJVKlnTDk3X348dab2TjgcmCYu3voMXlAXmh5qZmtBboDS8KuWKLSwhXbmTI3jZ05edx2fmd+Mbw7dWtVD7oskSov3E/XjKDkQusF7n641HhLYI+7F5lZZ6AbsC6sSiUq7T6Yx7TXVvDa11vp2aYhT9+cRL/2TYIuS0RCwj0n/xegNvBO6ONw33xU8nzgXjMrBIqA2919T5j7kiji7sz7eivT5i3nYF4hv/pOd26/oIsaiolEmXA/XdP1GOMpQEo425botXXfEabOTee9VTs4M74JM67qR/fWDYMuS0TKoN94lZNWXOy8tHgTD81fRVGx87vLezPu7AQ1FBOJYgp5OSnrdx0iOSWVL9bv4ZyuzXloTD/im9cLuiwROQGFvBxXYVExz366nkcXrKZWjWrMuCqRa5PUUEykslDIyzGtzD7ApJRUUrP2c0nv1tx3ZV9aN1JDMZHKRCEv/yWvsIgn3svkyQ/W0qReTZ64YQAjE9vo6F2kElLIy7d8tWkvk2alsmbHQcYOaMdd3+1NUzUUE6m0FPICwOH8Qh55ezXPfbaeuEZ1eO6Hg7ioR6ugyxKRMCnkhU/W7CJ5dipZe49w89COTBzRkwa19dIQiQV6J1dh+48U8MAbK/jnkiw6t6jPP28byuBOzYIuS0QiSCFfRb29fBt3zU1n96F8fnxhF34+rBt1aqqhmEisUchXMTtz8pg2bzlvpGXTO64Rz/5gEH3bNQ66LBEpJwr5KsLdmf3VFu59fQVH8ov47aU9mHB+Z2pWV0MxkVimkK8Ctuw7wp2z0/hw9U4GdmzKjKsS6dpKDcVEqgKFfAwrLnb+/sVGZry5CgemjerNzUMTqKaGYiJVhkI+Rq3deZDklFQWb9jLed1a8OCYRDo0U0MxkapGIR9jCoqKefrjdfxx4Rrq1qzOI9ecwVUD2qklgUgVFe6f/5sG3ArsDA3d6e7zQ+smA7dQ8pehfubub4ezLzmx9C37mZSSyvKtB7isbxvuGd2HVg3VUEykKovEkfxj7v5I6QEz6w1cB/QB2gILzay7uxdFYH9ylNyCIv783hqe+nAdTevV4q83DuCyxLigyxKRKFBep2tGAy+7ex6w3swygcHAonLaX5W1dOMeJs5KZe3OQ1w9sD1Tv9uLJvXUUExESkQi5O8ws5uBJcCv3X0v0A74vNR9skJjEiGH8gr5/dsZPL9oA20b1+WF8YM5v3vLoMsSkShzwpA3s4VAmzJWTQH+CtwHeOjro8B4oKyrfH6M7U8AJgDEx8efVNFV3UerdzJ5dhpb9x9h3NAEfntpD+qroZiIlOGEyeDuw09mQ2b2NPB66GYW0KHU6vbA1mNsfyYwEyApKanMbwRSYt/hfO5/YyWzlmbRpWV9/nXbUJIS1FBMRI4t3E/XxLl7dujmGCA9tDwP+IeZ/YGSC6/dgC/D2VdV92ZaNne9upy9h/O546Ku3HFxVzUUE5ETCvdn/IfNrD8lp2I2ALcBuPtyM/snsAIoBH6qT9acnh0Hcvndq8t5a/k2+rRtxPPjB9GnrRqKicjJCSvk3f2m46x7AHggnO1XZe7OrKVZ3Pf6CnILi5k0oie3nteJGmooJiKnQFfrotDmPYe5c04aH6/ZxaCEpky/qh9dWjYIuiwRqYQU8lGkqNh5YdEGfv92BgbcN7oPNw7pqIZiInLaFPJRInNHDpNS0li6cS8XdG/JA2P60r6pGoqJSHgU8gErKCrmfz5cy5/ezaRe7eo8es0ZjFVDMRGJEIV8gNKy9jMxJZWV2Qf4bmIc067oQ8uGtYMuS0RiiEI+ALkFRfxx4Rqe/ngdzerX4qnvD2RE37J+qVhEJDwK+Qr2xbrdJM9OY/2uQ3wvqQN3juxF43o1gy5LRGKUQr6C5OQW8PBbGfzt8410aFaXv98yhHO7tQi6LBGJcQr5CvB+xg6mzE4j+0Au48/pxG8u7U69Wpp6ESl/SppytPdQPve9voLZ/95Ct1YNSPnx2QyIbxp0WSJShSjky4G7Mz9tG3fPS2ff4QJ+NqwbP72oC7VrqKGYiFQshXyE7TiQy9S56SxYsZ1+7Rvzt1uG0CuuUdBliUgVpZCPEHfnX0uyuO+NFeQXFnPnyJ6MP0cNxUQkWAr5CNi0u6Sh2CeZuxjSqRkzrupHQov6QZclIqKQD0dRsfN/n23gkbczqF7NeGBMX64fFK+GYiISNRTyp2nN9hwmpqTy7037uLhnKx4Y05e4xnWDLktE5FsU8qcov7CYpz5cy1/ey6R+7eo8fl1/rjijrRqKiUhUCvdvvL4C9AjdbALsc/f+ZpYArAQyQus+d/fbw9lXNEjN2sfEWams2pbDqDPaMm1Ub5o3UEMxEYle4f75v+99s2xmjwL7S61e6+79w9l+tMgtKOKxd1bz9MfraNmwNk/fnMR3ercOuiwRkROKyOkaKzlXcS1wcSS2F02+WLebSSmpbNh9mOsGdWDyyF40rquGYiJSOUTqnPx5wHZ3X1NqrJOZ/Rs4AEx194/LeqCZTQAmAMTHx0eonPDl5BYw/c1VvPjFJuKb1eMfPxrC2V3VUExEKpcThryZLQTKanY+xd1fDS1fD7xUal02EO/uu81sIDDXzPq4+4GjN+LuM4GZAElJSX6q/4Hy8N6q7UyZk872A7n86NxO/PqSHtStpZYEIlL5nDDk3X348dabWQ1gLDCw1GPygLzQ8lIzWwt0B5aEVW0523Mon3tfW87cZVvp3roBT954NmeqoZiIVGKROF0zHFjl7lnfDJhZS2CPuxeZWWegG7AuAvsqF+7Oa6nZTJu3nJzcAn4+rBs/vagrtWqoJYGIVG6RCPnr+PapGoDzgXvNrBAoAm539z0R2FfEbdufy9S5aSxcuYMz2jdmxtVD6NlGDcVEJDaEHfLu/oMyxlKAlHC3XZ7cnZcXb+bBN1ZSUFzMlJG9GH9uJ6qrJYGIxJAq+RuvG3cfIjkljUXrdjO0c3OmX5VIx+ZqKCYisadKhXxRsfPcp+t5ZEEGNatV48ExiVw/uINaEohIzKoyIZ+xraSh2Neb9zG8VyvuvzKRNo3rBF2WiEi5ivmQzy8s5skPMnni/Uwa1anJn68/k8v7xenoXUSqhJgO+WWb9zFpVioZ23O4sn9bfjeqD83q1wq6LBGRChOTIX8kv4hHF2Tw7KfradWwDs+MS2JYLzUUE5GqJ+ZC/rPMXSTPTmPTnsPcOCSe5Mt60rCOGoqJSNUUMyG//0gBD81fycuLN5PQvB4vTziLszo3D7osEZFAxUTIp2bt49YXlrAzJ4/bzu/ML4Z3V0MxERFiJOTjm9Wje+uGPH1zEv3aNwm6HBGRqBETId+kXi3+dsuQoMsQEYk6arMoIhLDFPIiIjFMIS8iEsMU8iIiMUwhLyISwxTyIiIxTCEvIhLDFPIiIjHM3D3oGv7DzHYCG8PYRAtgV4TKiaRorQtU2+lSbacuWuuCyl9bR3dvWdaKqAr5cJnZEndPCrqOo0VrXaDaTpdqO3XRWhfEdm06XSMiEsMU8iIiMSzWQn5m0AUcQ7TWBartdKm2UxetdUEM1xZT5+RFROTbYu1IXkRESlHIi4jEsEoZ8mZ2jZktN7NiM0s6at1kM8s0swwzu7TU+EAzSwut+5OZWQXU+YqZLQv922Bmy0LjCWZ2pNS6p8q7ljJqm2ZmW0rVMLLUujLnsAJr+72ZrTKzVDObY2ZNQuPRMG8jQvOSaWbJFb3/o2rpYGbvm9nK0Pvh56HxYz63FVzfhtB7bpmZLQmNNTOzd8xsTehr0wDq6lFqbpaZ2QEz+0VQ82Zmz5rZDjNLLzV2zHk65fenu1e6f0AvoAfwAZBUarw38DVQG+gErAWqh9Z9CQwFDHgTuKyCa34U+F1oOQFID3gOpwG/KWP8mHNYgbVdAtQILc8AZkTDvAHVQ/PRGagVmqfeAdYTBwwILTcEVoeevzKf2wDq2wC0OGrsYSA5tJz8zXMb8HO6DegY1LwB5wMDSr+2jzVPp/P+rJRH8u6+0t0zylg1GnjZ3fPcfT2QCQw2szigkbsv8pKZegG4sqLqDf3UcC3wUkXtMwxlzmFFFuDuC9y9MHTzc6B9Re7/OAYDme6+zt3zgZcpma9AuHu2u38VWs4BVgLtgqrnJI0Gng8tP08Fvg+PYRiw1t3D+U37sLj7R8Ceo4aPNU+n/P6slCF/HO2AzaVuZ4XG2oWWjx6vKOcB2919TamxTmb2bzP70MzOq8BaSrsjdErk2VI/Dh5rDoMynpKfvL4R5LxF29z8h5klAGcCX4SGynpuK5oDC8xsqZlNCI21dvdsKPkmBbQKqLZvXMe3D76iYd7g2PN0yq/BqA15M1toZull/DvekVNZ59n9OOMVVef1fPuFlA3Eu/uZwK+Af5hZo0jUcwq1/RXoAvQP1fPoNw8rY1MR/5ztycybmU0BCoEXQ0MVMm/HK7uMscA/g2xmDYAU4BfufoBjP7cV7Rx3HwBcBvzUzM4PqI4ymVkt4ArgX6GhaJm34znl12CNciokbO4+/DQelgV0KHW7PbA1NN6+jPGwnahOM6sBjAUGlnpMHpAXWl5qZmuB7sCSSNR0srWVqvFp4PXQzWPNYUSdxLyNAy4HhoVOsVXYvB1HhczNqTCzmpQE/IvuPhvA3beXWl/6ua1Q7r419HWHmc2h5LTCdjOLc/fs0GnUHUHUFnIZ8NU38xUt8xZyrHk65ddg1B7Jn6Z5wHVmVtvMOgHdgC9DP+7kmNlZofPjNwOvVlBNw4FV7v6f00Vm1tLMqoeWO4fqXFdB9XxTQ1ypm2OAb67slzmHFVzbCGAScIW7Hy41HvS8LQa6mVmn0FHgdZTMVyBCr+VngJXu/odS48d6biuytvpm1vCbZUoupqdTMl/jQncbR8W9D8vyrZ+wo2HeSjnWPJ36+zPIK9thXI0eQ8l3tDxgO/B2qXVTKLninEGpT9AASZQ8aWuBvxD6bd8KqPX/gNuPGrsKWE7JVfKvgFEBzOHfgDQgNfTCiTvRHFZgbZmUnHdcFvr3VBTN20hKPsWyFphS0fs/qpZzKflRPbXUXI083nNbgbV1Dj1PX4eesymh8ebAu8Ca0NdmAc1dPWA30LjUWCDzRsk3mmygIJRrtxxvnk71/am2BiIiMSzWTteIiEgpCnkRkRimkBcRiWEKeRGRGKaQFxGJYQp5EZEYppAXEYlh/x8j2jW9foYlaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "\n",
    "plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73a661",
   "metadata": {},
   "source": [
    "### the 3 sets...  \n",
    "\n",
    "\n",
    "#### TRAINING SET ==  the model learns from this data, which is typically 70-80 %  of the total data..\n",
    "\n",
    "#### VALIDATION SET ==  the model gets tuned on this data, which is 10-15% of data\n",
    "\n",
    "#### TEST SET  == the model gets evaluated on this data to test what it learned, which is 10- 15 5 of data avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45656f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the lenght of the data/samples\n",
    "\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7fe8f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "\n",
    "\n",
    "X_train = X[:40]    # first 40 are training samples (80 % of data)\n",
    "Y_train = Y[:40]\n",
    "\n",
    "X_test = X[40:]   #  last 10 are testing samples (20% pof data)\n",
    "Y_test = X[40:]\n",
    "\n",
    "\n",
    "\n",
    "len (X_train),len (X_test), len (Y_train),len (Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77317446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing the data\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "\n",
    "# plot the training data in blue\n",
    "plt.scatter(X_train, Y_train , c = 'b', label = 'Training data')\n",
    "\n",
    "# plot the test  in red\n",
    "plt.scatter(X_test, Y_test , c = 'r', label = 'test data')\n",
    "\n",
    "\n",
    "# show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac789da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 55.9795 - mae: 55.9795\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.7081 - mae: 21.7081\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5143 - mae: 9.5143\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 933us/step - loss: 10.4132 - mae: 10.4132\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6483 - mae: 9.6483\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7544 - mae: 8.7544\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0720 - mae: 9.0720\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.1882 - mae: 19.1882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.3662 - mae: 10.3662\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.5039 - mae: 8.5039\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.8681 - mae: 10.8681\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.9118 - mae: 9.9118\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.1362 - mae: 12.1362\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3588 - mae: 12.3588\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4453 - mae: 8.4453\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.4063 - mae: 13.4063\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1747 - mae: 11.1747\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3817 - mae: 18.3817\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 516us/step - loss: 15.0847 - mae: 15.0847\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.0536 - mae: 11.0536\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.1868 - mae: 8.1868\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5088 - mae: 9.5088\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6776 - mae: 7.6776\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.1550 - mae: 13.1550\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4558 - mae: 16.4558\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1968 - mae: 13.1968\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.2934 - mae: 14.2934\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 991us/step - loss: 10.0852 - mae: 10.0852\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3905 - mae: 16.3905\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.6073 - mae: 23.6073\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 959us/step - loss: 7.6261 - mae: 7.6261\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3243 - mae: 9.3243\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7108 - mae: 13.7108\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1550 - mae: 11.1550\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3636 - mae: 13.3636\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 9.4737 - mae: 9.4737\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1304 - mae: 10.1304\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.2069 - mae: 10.2069\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9462 - mae: 10.9462\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.9353 - mae: 7.9353\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.0864 - mae: 10.0864\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.7050 - mae: 8.7050\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 981us/step - loss: 12.1840 - mae: 12.1840\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.8342 - mae: 13.8342\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 934us/step - loss: 8.4989 - mae: 8.4989\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 970us/step - loss: 9.1300 - mae: 9.1300\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6098 - mae: 10.6098\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 787us/step - loss: 7.7485 - mae: 7.7485\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5328 - mae: 9.5328\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1648 - mae: 9.1648\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3265 - mae: 16.3265\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.1553 - mae: 14.1553\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 899us/step - loss: 21.1745 - mae: 21.1745\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3654 - mae: 16.3654\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.0170 - mae: 10.0170\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.9547 - mae: 9.9547\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2176 - mae: 9.2176\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.4192 - mae: 8.4192\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4866 - mae: 9.4866\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 986us/step - loss: 11.4228 - mae: 11.4228\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.7254 - mae: 11.7254\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0867 - mae: 7.0867\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.0038 - mae: 17.0038\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4902 - mae: 12.4902\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0551 - mae: 13.0551\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.0814 - mae: 8.0814\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.2159 - mae: 10.2159\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4023 - mae: 12.4023\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 973us/step - loss: 9.0488 - mae: 9.0488\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 821us/step - loss: 10.0331 - mae: 10.0331\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0505 - mae: 10.0505\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.5985 - mae: 12.5985\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4208 - mae: 10.4208\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7196 - mae: 9.7196\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 960us/step - loss: 11.2170 - mae: 11.2170\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3615 - mae: 8.3615\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1148 - mae: 9.1148\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.5520 - mae: 19.5520\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 626us/step - loss: 14.8677 - mae: 14.8677\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 930us/step - loss: 9.0463 - mae: 9.0463\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.0004 - mae: 13.0004\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9222 - mae: 7.9222\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7066 - mae: 7.7066\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0626 - mae: 10.0626\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.2665 - mae: 9.2665\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.0524 - mae: 12.0524\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6726 - mae: 10.6726\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.2799 - mae: 7.2799\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.8151 - mae: 12.8151\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.4922 - mae: 7.4922\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.7638 - mae: 6.7638\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.9652 - mae: 11.9652\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 8.8964 - mae: 8.8964\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7352 - mae: 7.7352\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.7628 - mae: 6.7628\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.6489 - mae: 8.6489\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4012 - mae: 9.4012\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1373 - mae: 9.1373\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4929 - mae: 10.4929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0cfadac0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let have a look at how to build a NN for our data\n",
    "\n",
    "\n",
    "\n",
    "# 1. create a model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics= ['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27b8ca",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dbca8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a20481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let create a model which build automatically by defining the input_shape argument\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[1])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics= ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f66d1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76535b",
   "metadata": {},
   "source": [
    "##### Total params= total no of parameters in the model\n",
    "\n",
    "##### trainable pramaters = these are the parameters (patterns) the model can update as it trains\n",
    "\n",
    "##### Non-trainable parameters = these params arent updates during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2041757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let create a model which build automatically by defining the input_shape argument \n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[1])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics= ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e03b1d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d143476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 980us/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 975us/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 977us/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 976us/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 960us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 989us/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 771us/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 860us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 731us/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 971us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 822us/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 907us/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 525us/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0d127cd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets fit the model to training data\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X_train, Y_train, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "180b5d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6879c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let create a model which build automatically by defining the input_shape argument \n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics= ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd45747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 42.5345 - mae: 42.5345\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 39.1160 - mae: 39.1160\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 835us/step - loss: 35.5600 - mae: 35.5600\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 32.2152 - mae: 32.2152\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.0249 - mae: 29.0249\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.1898 - mae: 26.1898\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.5915 - mae: 23.5915\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.9329 - mae: 20.9329\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.2865 - mae: 18.2865\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.2482 - mae: 16.2482\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4797 - mae: 14.4797\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 982us/step - loss: 12.6965 - mae: 12.6965\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.1948 - mae: 11.1948\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.9701 - mae: 9.9701\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.0727 - mae: 9.0727\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.5387 - mae: 8.5387\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.2167 - mae: 8.2167\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.9082 - mae: 7.9082\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8017 - mae: 7.8017\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6392 - mae: 7.6392\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 975us/step - loss: 7.6167 - mae: 7.6167\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6665 - mae: 7.6665\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6365 - mae: 7.6365\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7477 - mae: 7.7477\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7342 - mae: 7.7342\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6447 - mae: 7.6447\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 934us/step - loss: 7.6164 - mae: 7.6164\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 957us/step - loss: 7.6190 - mae: 7.6190\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6789 - mae: 7.6789\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.6073 - mae: 7.6073\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7203 - mae: 7.7203\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7552 - mae: 7.7552\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6433 - mae: 7.6433\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6076 - mae: 7.6076\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7209 - mae: 7.7209\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9958 - mae: 7.9958\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 980us/step - loss: 7.6677 - mae: 7.6677\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 842us/step - loss: 7.6319 - mae: 7.6319\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5987 - mae: 7.5987\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.6008 - mae: 7.6008\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6613 - mae: 7.6613\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5870 - mae: 7.5870\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.5932 - mae: 7.5932\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6238 - mae: 7.6238\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7125 - mae: 7.7125\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8035 - mae: 7.8035\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6771 - mae: 7.6771\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7398 - mae: 7.7398\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6553 - mae: 7.6553\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8126 - mae: 7.8126\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6137 - mae: 7.6137\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6961 - mae: 7.6961\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7108 - mae: 7.7108\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 790us/step - loss: 7.7654 - mae: 7.7654\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5848 - mae: 7.5848\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6266 - mae: 7.6266\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8786 - mae: 7.8786\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 972us/step - loss: 7.6702 - mae: 7.6702\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.5831 - mae: 7.5831\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5864 - mae: 7.5864\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.5839 - mae: 7.5839\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6504 - mae: 7.6504\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6564 - mae: 7.6564\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 992us/step - loss: 7.8055 - mae: 7.8055\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.5815 - mae: 7.5815\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5663 - mae: 7.5663\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6074 - mae: 7.6074\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.5633 - mae: 7.5633\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 990us/step - loss: 7.6111 - mae: 7.6111\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.6084 - mae: 7.6084\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9296 - mae: 7.9296\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6909 - mae: 7.6909\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6349 - mae: 7.6349\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7197 - mae: 7.7197\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6169 - mae: 7.6169\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 859us/step - loss: 7.6127 - mae: 7.6127\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 515us/step - loss: 7.5649 - mae: 7.5649\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 515us/step - loss: 7.5988 - mae: 7.5988\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 537us/step - loss: 7.5797 - mae: 7.5797\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6160 - mae: 7.6160\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6053 - mae: 7.6053\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.5498 - mae: 7.5498\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5904 - mae: 7.5904\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5687 - mae: 7.5687\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.5889 - mae: 7.5889\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 993us/step - loss: 7.6362 - mae: 7.6362\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 7.8440 - mae: 7.8440\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9867 - mae: 7.9867\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.5684 - mae: 7.5684\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5749 - mae: 7.5749\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5861 - mae: 7.5861\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6026 - mae: 7.6026\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5932 - mae: 7.5932\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5431 - mae: 7.5431\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.7128 - mae: 7.7128\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 985us/step - loss: 7.5936 - mae: 7.5936\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 933us/step - loss: 7.6586 - mae: 7.6586\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5598 - mae: 7.5598\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5359 - mae: 7.5359\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.5413 - mae: 7.5413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0d3b05e0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets fit the model to training data\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X_train, Y_train, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99fdcb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "852335e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot, graphviz and pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "687fbe65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAC4CAYAAAAMsPCPAAAABmJLR0QA/wD/AP+gvaeTAAAfKElEQVR4nO3dT2gb2R0H8K+69RZykcjB7sbgw+LG+FAEW0hMm2LiDSwJjBbaOPUf3PQgGxlK2iU+NK6MMUm9e5BhSQ42ki5B2Baby6LBCQVbJaG7kRcKUksPMcsucumy1knDntqwfT1438uM/lijvyNZ3w+IXY1G835S5PnNvHnzey4hhAARERGA7zkdABERtQ8mBSIiUpgUiIhIYVIgIiLl+4ULvv76a7z33nv49ttvnYiHiIhaZGZmBpqmWZYVnSkkk0nE4/GWBUVE9uzv72N/f9/pMDrCo0ePcHh46HQYbe3Ro0cl9/VFZwrSRx991NSAiKg609PTAIDNzU2HI2l/LpcLt27dwtTUlNOhtC35eyrEawpERKQwKRARkcKkQERECpMCEREpTApERKQwKRB1oaWlJSwtLTkdRttwuVyWRym5XA5ra2stjWttbQ2GYZR8zU7MtWBSIKKWMwyjoTuyRhFCoFTh6Fwuh+XlZcuNXvF4HD6fDy6XC/Pz88jlclW3ZxgGUqkUIpEIfD5f0etXrlzBzMxMyW2Xi7VeTApEXeju3bu4e/euY+0/e/bMsbarZRgG/H4/bt68ifPnzwMAIpEIent7kUgkIITA6Ogo/H4/MplMVdsOhULY2dnB3NwcdF0vet3r9WJxcRF+v7/sGUOjMSkQUUsZhoFIJOJ0GLZFo1F4vV6MjIyoZXNzc5aj94mJCei6XnWXnJ3kPDIygv7+fkSj0eoCrxGTAlGXyeVyquuj1HNd1+FyueDz+VSpiFwuB13X1TqRSER1mxwcHKhtl+rjLlwWCoXUUbF5eTte58jlclhYWMDly5cty8PhMLa2torW7+/vb0oc4+PjWFhYqKmLqlpMCkRdxu/3Y3JyUu2Yzc9TqRQ0TUM2m4Wu63j//fcBAH19ffD5fGqd2dlZ5PN5AMDQ0JBKDEdHR0XtZbNZy3PzkXGz+sUbRdaaGhwctCyfnZ1FIpFQz+XnDwQCTYlDtt+K2ldMCkRdxrwzK3wuu0gGBgYAABsbGwBg2XHLddxut9oJygTT29tb1J7cViVOX+co5bPPPgNQ+TPEYjGk02l4vd6mxOF2uwHAclbWLEwKRFQzuRNcWFhwOJLmuHfvXsV1kskkrl+/3rSEALxKCq34npkUiIjqcObMmaYmhFZjUiCiujWrL73dxeNxy6ik04BJgYhqJvu4r1275nAkzREKhQCg7D0CExMTrQwHwWCw6W0wKRB1GfOwxlwuZ3kud37mnWDhMEg5W5dhGIjFYtA0zXKnrzxrkAkjlUqp1+bn5wFArW8uHdGOQ1LlzWrlkkK5mNfW1uByuWzdzGbedrl25NDgCxcuVNxevZgUiLpMX1+f5f/Nzz0ej+W/hesDwPDwMHw+HzweDwYGBhCLxSyv37lzB5qmYWhoCLquY2RkBJqmYXt7GysrKwBeDUt98OABZmZmGvsBG+jixYsAgK+++qqq9+XzeQQCgYpJzuVyWb5rj8dTsvyHbF/G00xlp+MkotPJzn0BJ63j9XqLhrWaDQwMnDjsVW6jsI12G44KHA+xDYVC+OSTT0peOygXs1xeqp6Rmd17NHZ2dhAKhUoO+W00nikQEZ3A7/fj6dOnlm4wO1KpFBYXF+tuP5PJIJPJwO/3170tO5gUiKiiwusQ3cTtdiMajWJ1ddV2wbtkMomzZ8/WPTLp4OAAGxsbiEaj6l6FZmtaUiisp0Ina8eLbERS4XWI06rc3AS9vb2IxWLY3d21tZ2xsTF1kboeuq5jZWWlZLdRo+dRkJqWFJaXly31VTrN4eEh5ufnVdGvZDJZcj1ZJEzWhelUtdS3L5zko1k/UjsK42+n2E4DWaOo3WsV1crO53O73bh9+3ZL47p9+3bZ6wjN+jdpWlJYX19v1qabzjAMZDIZrK+vI5/PY3R0FG+//XbRTj8ejyMSiSAWiyEWi+Hx48c1lwR2uu5LLfXthRCqKBpwPOLCqR1GYfxCCEtxNidjI+okvKZQwrNnz9Q4arfbrW5QMXeFHR4eYnJyEouLi3C73ao42NzcXNUTbTitnvr25n7OVvV5FioXv/kIy6nYiDpNw5KCYRiIx+OqDnu5an7yZhW5nuyWsVPTXZLvj0QiyOVyRd0C5dqwy3wjjpn5Vv5PP/0UAHDu3Dm17I033gDwqrKiXaetvn27xF8NmVjk+5eWliy/I/kwz9Frfs38ucr9vuXnNQwD8/PzvIZE7UkU2NzcFCUWV6RpmggEAiKfzwshhNje3hYALNs6OjoSmqaJ7e1tIYQQe3t7AoBIp9NC0zS1/vPnz4UQQmSzWQFABAIBtY1QKCSy2awQQoh8Pi+CwaDtNmqVz+cFAJFIJNSyQCBQ8nsCIDRNq2r75s9e+LzcdyFfN6+Tz+dVXC9evBBCHH8fhf8OclvmZYXPhRAiGAyKYDBYMf7C97ZL/CctLyTbPTo6Kor1+fPnRb9D82c9OjpSsdr9fafT6ZLbO8nU1JSYmpqq6j3dCoDY3Nx0Ooy2Vu731JCkkEgkLH/IQrzakZq3JROFJQBA7XhK/QGX+uOXf4RCvNpp2G2jFnt7e0LTNJXwysV60vJK7Ozk7KyTTqcFABEKhereVq2xt1P8dj9XMBi07KQL3xcKhQQAdUAiY5UJQAj7v2/z76gaTAr2MSlU1tSkcNJRc7kjyMJHqfVLLZNtbW9vl/zjqtRGLTRNU0ez5eKqtLySRiWFRm+rltjbKf5qP1c2m1UJwPw+mazC4bBaZj5rFaK233c1pqamym6fDz5qeZRKCg0pcyFnZ6pE9vuKOkaBvPfee/j3v/+NyclJAMf9yeZhYo1owywej0PTtKKbUDRNKzsEtVvLCHe6SCQCXdcRCoWKJjPxer1qIMGNGzcAAJ9//rllRq5G//ZKuXTpEm7dutW07Z8WN27cwK1bt3Dp0iWnQ2lb9+/fL/1CYZao5UwB32WdSsvlc3M3U6XtlNu27JMFSnc1lGujGul0umy3UzgcFoC1K0v2RZuPJu0q911Vu45cflJXSDXbqiX2doq/0ueS7ciuH3nkX+p98mxhe3tbJBKJsmeP1fy+q8HuI/sAdh9VUu731JDRR+FwGAAqDsWU68ViMVUi1lw61w6XywXDMOD1erG+vo50Om05qmtEG/I9u7u7lnsHMpmMKv37zjvvAAC++OIL9bqsZChfc0Kn17dvZfypVAqjo6MAoM48T5qLV54tTE5OIhKJFJ09Nuq3R+SowixRy5mCPELWNE0dacmRFzAd9ZlHkpgf2WzW8pq8VmC+WC2PyIHjC3eyHdkHLJ3Uhl1yFEmp7ZhHIIXDYTXiSo6cqeUswRzz0dFRVd8FvjtylesEg8Gi0U+FI3rkaBrzv438vEdHR+r7tDP6yByXjLVd4i81ckmS25Cj0uT7s9msePHiRVGshe8r9e9s9/ddK54p2AeeKVTU1AvNQhzvnOUfbyAQsAzPK+xikcNIA4FA0em6+Q+n3DL5h4+CrqNKbdglP0epR2HXgBx5pWma2Nvbq6odqVxbdr4LuWOTO7VwOFx0AT6bzarXZVIr/LeRXSPBYFAtq5QUKsXtZPx2Y5NtFb5fjkYq9dvRNK1sF5Gd33e1Q5YlJgX7mBQqK/d7cglhvSq2tbWF6elplgToAPImrU79t+rE+A3DwB/+8AdHyrhMT08DADY3N1vedqdxuVzY3NzE1NSU06G0rXK/J5a5IKrCRx99hPHxcafDIGoaJoUO1en17Tsp/qWlJUs5i7GxMadDogazU03XiUEDa2trZedtblYF4K5KCuXKKTfry21me51e376T4pcjksLhcFtOGdkqtZRXb6ft2yHKlKHO5XJYXl621EWT9b1kza5aDm4Mw0AqlUIkEik598yVK1cwMzNTctvlYq1XVyUF+SVWenRCe82KuVU6Kf7Z2VkIITA7O+t0KI6qpbx6O22/VoZhwO/34+bNm2rinEgkgt7eXiQSCQghMDo6Cr/fX3WF5FAohJ2dHczNzZW8Gdbr9WJxcRF+v7/sGUOjdVVSIKLa1FNevR22X49oNAqv12u5L2Vubs5y9D4xMQFd16uufGtnHpWRkRH09/cjGo1WF3iNmBSITjlzWXtzyXmp1vLk7Vy+vVFyuRwWFhZw+fJly/JwOIytra2i9fv7+5sSx/j4OBYWFlpy/Y1JgeiUm5mZwTfffAMhjmej03Xd0h1hnqFOymazlufmo1nZ5dfX16emoU2lUpidnVUz8Q0NDanEUOv228H+/j4AYHBw0LJ8dnYWiURCPZeftVl1z2T7Mp5mYlIgOsWSySR0Xce7774L4Hg2usXFRei6jidPnqhlhU4q9yGZd9yya0XOQAi8KhBY6/YB56eplRNmVYo3FoshnU7D6/U2JQ45c2C5ycsaiUmB6BR79OgRAOuOeXh4GABKdn80gtwxFlaa7UT37t2ruE4ymcT169eblhCAV0mhFd8pkwLRKVaqrL3cwZQr/U7VOXPmTFMTQqsxKRCdYnJcfakLlM2e96Mb5hWJx+NF1XI7HZMC0Skma/+YS7zLC8zNKtfR6eXbzUKhEACUvUdgYmKileEgGAw2vQ0mBaJT7OrVq9A0Daurq+ps4cmTJwgEApZyHfKoXu7QU6mUek3OIWI+6ygs9xCPxwEc7zxjsRg0TbPc/Vvr9p0ekipvViuXFMrFt7a2BpfLZetmNvO2y7VzeHgIALhw4ULF7dWLSYHoFHO73YhGo9A0DX19fWr8/wcffGBZ786dO9A0DUNDQ9B1HSMjI9A0Ddvb21hZWQHwatjogwcPMDMzY3n/8PAwfD4fPB4PBgYGEIvFGrp9p1y8eBHAqwm07Mrn8wgEAhUTmsvlgsfjUc89Hk/JUh+yfRlPM7F0NlGHaMfS2e1a/rza0tknfQ551mKeC94un89nuZ+hVktLS/B4PCVjqPXfgKWziYhq4Pf78fTpU0uXlx2pVAqLi4t1t5/JZJDJZOD3++velh1MCkRUk04qf14P2QW3urpqu+BdMpnE2bNn6x6ZdHBwgI2NDUSjUTWUuNmYFIioJp1U/tyucuXse3t7EYvFsLu7a2s7Y2Nj6iJ1PXRdx8rKSsm7whtd6l/6fsO3SERdod2uI9TDzmdxu901XVeox0ntNev755kCEREpTApERKQwKRARkcKkQEREStkLzbLkLhG1B1nqgH+b9uzv76Onp8fpMNrWo0ePSte/EgX29/cFAD744IMPPk75449//GNhChBFZS6IulG1ZRGITiteUyAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIoVJgYiIFCYFIiJSmBSIiEhhUiAiIuX7TgdA1GrpdBp//vOfi5bruo5//etf6vng4CB++ctftjI0Ise5hBDC6SCIWul3v/sd7t+/jx/84Adl1/nPf/4DAOCfB3Ubdh9R1/nFL34B4HjHX+7x+uuv47e//a3DkRK1Hs8UqOv873//Q39/P77++usT1/vrX/+Kn/3sZy2Kiqg98EyBus73vvc9TE9P4/XXXy+7zrlz5/DTn/60hVERtQcmBepKk5OT+O9//1vytZ6eHvz617+Gy+VqcVREzmP3EXWtN998E19++WXJ1/7+97/jxz/+cYsjInIezxSoa/3mN79BT09P0fIf/ehHTAjUtZgUqGtNTk7i5cuXlmU9PT24efOmQxEROY/dR9TVvF4v/vGPf6j7EVwuFz7//HO8+eabDkdG5AyeKVBXu3nzJl577TUAxwnhrbfeYkKgrsakQF1tYmIC3377LQDgtddew8zMjMMRETmLSYG62rlz5/Dzn/8cwPFNbb/61a8cjojIWUwK1PWmp6cBAD/5yU/wwx/+0OFoiJzV0Reag8Eg/vSnPzkdBhGR8vrrr6uCip2oo0tnf/nll+jp6cHm5qbToVCHMwwDDx8+BADcunXL4Wja340bN3Dr1i1cunTJ6VDaytbWFj7++GOnw6hLRycFABgfH8f4+LjTYdAp8Je//AUA+Huy6eLFi/yuCrx8+bLjkwKvKRARkcKkQERECpMCEREpTApERKQwKRARkcKkQNQES0tLWFpacjqMjpHL5bC2ttbSNtfW1mAYRkvb7ARMCkSnkGEYHTNzXC6Xw/LyMjRNU8vi8Th8Ph9cLhfm5+eRy+Wq3q5hGEilUohEIvD5fEWvX7lyBTMzMzVt+zRjUiBqgrt37+Lu3buOtf/s2TPH2q6GYRjw+/24efMmzp8/DwCIRCLo7e1FIpGAEAKjo6Pw+/3IZDJVbTsUCmFnZwdzc3PQdb3oda/Xi8XFRfj9fp4xmDApEJ0yhmEgEok4HYYt0WgUXq8XIyMjatnc3Jzl6H1iYgK6rlfdHWcnMY+MjKC/vx/RaLS6wE8xJgWiBsvlcqr7o9RzXdfhcrng8/lweHio1tF1Xa0TiURU18nBwYHatsvlUo9yy0KhkDoyNi9vt+scuVwOCwsLuHz5smV5OBzG1tZW0fr9/f1NiWN8fBwLCwvsRvoOkwJRg/n9fkxOTqods/l5KpWCpmnIZrPQdR3vv/8+AKCvrw8+n0+tMzs7i3w+DwAYGhpSieHo6KiovWw2a3luPjoWQqBda17u7+8DAAYHBy3LZ2dnkUgk1HP52QOBQFPikO3LeLodkwJRg5l3aIXPZTfJwMAAAGBjYwMALDtuuY7b7VY7Qplgent7i9qT26rE6eschT777DMAleOPxWJIp9Pwer1NicPtdgOA5YysmzEpELUxuSNcWFhwOJLGu3fvXsV1kskkrl+/3rSEALxKCqfxO64FkwIRta0zZ840NSFQMSYFog7QrP70dhaPxy2jkqg1mBSI2pjs57527ZrDkTReKBQCgLL3CExMTLQyHASDwZa2166YFIgazDy0MZfLWZ7LHaB5R1g4FDIej6t1YrEYNE2z3O0rzxpkwkilUuq1+fl5AFDrm8tHtNuQVHmzWrmkUC7etbU1uFwuWzezmbddrh05LPjChQsVt9cNmBSIGqyvr8/y/+bnHo/H8t/C9QFgeHgYPp8PHo8HAwMDiMViltfv3LkDTdMwNDQEXdcxMjICTdOwvb2NlZUVAK+GpT548AAzMzON/YANcvHiRQDAV199VdX78vk8AoFAxQTncrks37PH4ylZ+kO2L+Ppdh0/HSdRu7FzX8BJ63i93qJhrWYDAwMnDnuV2yhso52GowLHw2tDoRA++eSTktcOysUrl5eqZ2Rm9/6MnZ0dhEKhksN9uxHPFIjIMX6/H0+fPrV0gdmRSqWwuLhYd/uZTAaZTAZ+v7/ubZ0WTAooLkNA1GqF1yG6hdvtRjQaxerqqu2Cd8lkEmfPnq17ZNLBwQE2NjYQjUbVvQrEpAAAWF5etpQl6DSHh4eYn59XtXKSyWTJ9WRtHVlOoVrmGjuFj7W1Nei6zmqTNSq8DtFNent7EYvFsLu7a2v9sbExdZG6HrquY2Vlhd1GBZgUAKyvrzsdQs0Mw0Amk8H6+jry+TxGR0fx9ttvF+304/E4IpEIYrEYYrEYHj9+XHUlTSGEpfZOPp9XtXWuXLmCSCTC+vQ1kt9jO9cqaia3243bt2+3tM3bt28zIZTApNDhnj17poYfut1uNbbb3BV2eHiIyclJLC4uwu12q5o6c3NzVdeoN/8RmU+5vV6vKj/M+vREnasrk4JhGIjH46p8cblCWHKMt1xPdsvYKYUsyfdHIhHkcrmiIXHl2rDLPH7dzHwH7KeffgoAOHfunFr2xhtvAHhVlAyofxx7b28vfv/730PX9aJJXjrhuyQiAKKDTU1Niampqarfp2maCAQCIp/PCyGE2N7eFgCE+es4OjoSmqaJ7e1tIYQQe3t7AoBIp9NC0zS1/vPnz4UQQmSzWQFABAIBtY1QKCSy2awQQoh8Pi+CwaDtNmqVz+cFAJFIJNSyQCAgSv1TAxCapqnnwWBQBIPBim0Uflel2jd/D53yXdb6e+pGAMTm5qbTYbSdzc3Nsn8bnaKjo6/ljziRSAgA4sWLF2qZ3JGZ/zFlojADoHaapXaMhcsAiKOjI/X86OioqjZqsbe3JzRNUwmvXKwnLa+k0vs69btkUrCPSaG005AUuu7mtcePHwOAZfRCqeFocuanwi6Ke/fu2b4JKBAIoK+vD9vb27h69Sp6e3stFxEb0UahDz/8UF07aBed9F0eHh7i0aNHttfvZvv7++jp6XE6jLZyKibqcTor1aOWIzvYPGout95Jrxcue/HihaV7JBQK2YqlVtvb2yIcDhctlzEUQkEXjV0nxS3PusxH6J3yXU5NTant8MFHPY9O1pUXmqtRz2xM58+fRyKRQDqdRiAQwMLCgipO1qg2pEwmg3/+85+YnZ0tes1cHE2SF3Hfeuututs2+9vf/gYARfPuAp3xXU5NTRUND+Wj+AEAm5ubjsfRbo/Nzc26fn/toOuSQjgcBoCKQzHlerFYTA2vNFectMPlcsEwDHi9XqyvryOdTltmd2pEG/I9u7u7lm6STCajKma+8847AIAvvvhCvS6LgMnXGiGXy+HDDz+EpmkYGxtTyzvpuyTqeqKD1dJ9JEe2aJqmRrPIkSrAq+4UeSGz8JHNZi2vyQu65ovV8oIocNyNItvJZrOWbo+T2rBLjroptR3zCKRwOKxGXOXzeREIBIq6muyMPjJ/TvPFbDmSSNM0ywXhTvoueaHZPoAXmks5DReaOzr6Wv+Is9msGqYZCAQswxnNO7RsNquGPgYCAbWDKdzxnLTs6OhIhEIhART3g5/Uhl3yc5R6mEdYCfFq5JWmaWJvb69oW5WSQrl25GeTQ0pL6YTvkknBPiaF0k5DUnAJ8V0HYQeanp4GgFPRj0fO4+/JPpfLhc3NTUxNTTkdSlvZ2trC9PQ0Oni32n3XFIiIqDwmBSIiUpgU2tRJZarND6JO066jwtbW1ljIEUwKbUtUMV6cTgfDMJqa6Ju9fTtyuRyWl5cthRxlQUQ5H0gtpdcNw0AqlUIkEjlxsqyT5hS5cuUKS7+DSYGobRRWlu207VdiGAb8fj9u3rypysxEIhH09vYikUhACIHR0VH4/f6qS7qHQiHs7Oxgbm6u7ARSleYU8Xq9WFxc7PrS70wKRG3AMIyqJz1qp+3bEY1G4fV6LdNozs3NWY7MJyYmoOt61SXc7969e2KNK7tzioyMjKC/v1/NDdKNmBSI6mSen8M834NU6hpQ4bJQKKSOcOXyXC6nujuA46Nq2cViLudR6/aB+ufQsCuXy2FhYaGo/Ek4HFbFDM36+/sb2r7dOUUAYHx8HAsLC13bjcSkQFSnmZkZfPPNNxDieLpSXdctXRDmKUylbDZreW4+ypXXi/r6+lTfdyqVwuzsLPL5PABgaGhIJYZat99Ksnro4OCgZfns7CwSiYR6Lj+TeZKoRnj69CkAYGBgQC2TswgWdjfJGE9FxdMaMCkQ1SGZTELXdbz77rsAjnc0i4uL0HUdT548UcsKmXdO5Zh33LLLRXZ7AK92ZrVuH6jc7dIo8mi8UlyxWAzpdBper7eh7W9sbJR9rTApyLLzjShU2YmYFIjqIOdeMO+Yh4eHAaBkt0gjyB2muSBgu7t3717FdZLJJK5fv97whFAtmRQ66fttJCYFojqUOgKVO5Vyo2CotDNnzjQtIZSbyxxofFdVp2NSIKpDqbkqpGbvbE7Tziwej1tGJTVaK+cU6XRMCkR1kAXhzHNVyAvM4+PjTWlT9nVfu3atKdtvhlAoBABlx/9PTEw0tf1a5hQJBoNNjaldMSkQ1eHq1avQNA2rq6vqKPTJkycIBAKWiYbkUb3coadSKfWanAzJfDRbWAYiHo8DON6pxmIxaJpm6RKpdfutGpIqb1YrlxTKxbG2tgaXy2XrZjbztgvbGRgYQDgcxsOHD2EYBgzDwMOHDxEOh4sufssziAsXLlRs8zRiUiCqg9vtRjQahaZp6OvrU+P/P/jgA8t6d+7cgaZpGBoagq7rGBkZgaZp2N7exsrKCoBXw0YfPHiAmZkZy/uHh4fh8/ng8XgwMDCAWCzW0O0328WLFwG8Ojq3K5/PIxAIVExcLpcLHo9HPfd4PEUlPWZnZ3Ht2jV4PB7MzMxgfHy85PS1MkYZc7fhfApE32nH35PcsbXbn2kt8ynIs5Pbt29X3Z7P57Pcz9BMS0tL8Hg8NcXJ+RSIiGzy+/14+vSppWvLjlQqhcXFxSZFZZXJZJDJZOD3+1vSXjtiUiBqU+aRMqeh5ILsaltdXbVd8C6ZTOLs2bNNHZkkHRwcYGNjA9FoVA0r7kZMCkRtqq+vr+T/d7Le3l7EYjHs7u7aWn9sbExdpG42XdexsrJS8g7xbvJ9pwMgotI6uV/6JG63u6b++mZrx5icwDMFIiJSmBSIiEhhUiAiIoVJgYiIlI6/0Ly1tYWXL186HQadAnJSlRs3bjgcSWe4f/8+Pv74Y6fDaCuylHon6+g7mnVdL7rdn4jISYODg1hdXXU6jJp1dFIgIqLG4jUFIiJSmBSIiEhhUiAiIoVJgYiIlP8DYd+plbZsxrQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "336c515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let create a model which build automatically by defining the input_shape argument \n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name= 'input_layer'),\n",
    "    tf.keras.layers.Dense(1, name = 'outpur_layer')\n",
    "], name= 'model_1')\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.SGD(),\n",
    "             metrics= ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "433104f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "outpur_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b59f23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 42.4539 - mae: 42.4539\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.9446 - mae: 18.9446\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.2156 - mae: 25.2156\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9857 - mae: 15.9857\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.6567 - mae: 16.6567\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.1580 - mae: 17.1580\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6542 - mae: 7.6542\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9159 - mae: 17.9159\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6230 - mae: 15.6230\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.5542 - mae: 6.5542\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8820 - mae: 13.8820\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9402 - mae: 14.9402\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.8448 - mae: 7.8448\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5208 - mae: 9.5208\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 987us/step - loss: 11.8443 - mae: 11.8443\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8258 - mae: 7.8258\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.2410 - mae: 6.2410\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6913 - mae: 8.6913\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.4454 - mae: 7.4454\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.9401 - mae: 4.9401\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.8700 - mae: 7.8700\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.8967 - mae: 5.8967\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.2914 - mae: 5.2914\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.0060 - mae: 7.0060\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 3.4989 - mae: 3.4989\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 3.9121 - mae: 3.9121\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5052 - mae: 2.5052\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 513us/step - loss: 2.8300 - mae: 2.8300\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 981us/step - loss: 1.8532 - mae: 1.8532\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0738 - mae: 1.0738\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 1.1352 - mae: 1.1352\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1144 - mae: 1.1144\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.5527 - mae: 1.5527\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9388 - mae: 0.9388\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8925 - mae: 0.8925\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5742 - mae: 1.5742\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7104 - mae: 0.7104\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5218 - mae: 1.5218\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9645 - mae: 0.9645\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9306 - mae: 0.9306\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7951 - mae: 0.7951\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6509 - mae: 1.6509\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7809 - mae: 0.7809\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5110 - mae: 0.5110\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.3691 - mae: 0.3691\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.2243 - mae: 0.2243\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.2195 - mae: 1.2195\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7835 - mae: 0.7835\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3018 - mae: 1.3018\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9715 - mae: 0.9715\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 776us/step - loss: 0.7241 - mae: 0.7241\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8442 - mae: 0.8442\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 992us/step - loss: 2.6305 - mae: 2.6305\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4138 - mae: 2.4138\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.9409 - mae: 1.9409\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1992 - mae: 2.1992\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9079 - mae: 0.9079\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1918 - mae: 0.1918\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8476 - mae: 0.8476\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9338 - mae: 0.9338\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3745 - mae: 2.3745\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4392 - mae: 1.4392\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6685 - mae: 2.6685\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.0454 - mae: 1.0454\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8034 - mae: 0.8034\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0605 - mae: 3.0605\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4232 - mae: 1.4232\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.4383 - mae: 1.4383\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0443 - mae: 1.0443\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6102 - mae: 0.6102\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 953us/step - loss: 1.0126 - mae: 1.0126\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0461 - mae: 1.0461\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6123 - mae: 0.6123\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.9165 - mae: 0.9165\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 2.2697 - mae: 2.2697\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 986us/step - loss: 1.8601 - mae: 1.8601\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 877us/step - loss: 1.5522 - mae: 1.5522\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9421 - mae: 0.9421\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5845 - mae: 0.5845\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5766 - mae: 1.5766\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7186 - mae: 0.7186\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2660 - mae: 0.2660\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6847 - mae: 0.6847\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6005 - mae: 0.6005\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2950 - mae: 0.2950\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.3329 - mae: 1.3329\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.9429 - mae: 0.9429\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.8713 - mae: 0.8713\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4768 - mae: 0.4768\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6417 - mae: 1.6417\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8549 - mae: 0.8549\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.0086 - mae: 3.0086\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 963us/step - loss: 1.2294 - mae: 1.2294\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1933 - mae: 1.1933\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9173 - mae: 0.9173\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 981us/step - loss: 0.7066 - mae: 0.7066\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4312 - mae: 0.4312\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8960 - mae: 0.8960\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7972 - mae: 0.7972\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6277 - mae: 0.6277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0d606460>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fintuning our model by addig activation fun, adding dense layer, changing the optimizers, etc.. \n",
    "\n",
    "\n",
    "# 1. Create the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = None),\n",
    "    tf.keras.layers.Dense(100, activation =None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "model.compile(loss= tf.keras.losses.mae,\n",
    "             optimizer= tf.keras.optimizers.Adam(lr=0.01),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X_train, Y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ceaa8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,401\n",
      "Trainable params: 10,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825987d",
   "metadata": {},
   "source": [
    "#### Visualizing our model predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0d93110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0D5B6E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 72.6226  ],\n",
       "       [ 76.785904],\n",
       "       [ 80.9492  ],\n",
       "       [ 85.1125  ],\n",
       "       [ 89.275795],\n",
       "       [ 93.43909 ],\n",
       "       [ 97.60239 ],\n",
       "       [101.7657  ],\n",
       "       [105.929   ],\n",
       "       [110.09229 ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make some predictions\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2cda814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19e13416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a plotting function\n",
    "\n",
    "def plot_predictions(train_data = X_train,\n",
    "                    train_labels = Y_train,\n",
    "                    test_data=X_test,\n",
    "                    test_labels=Y_test,\n",
    "                    predictions=Y_pred):\n",
    "    \"\"\"\n",
    "    Plot training data, test data and compares predictions to ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(train_data, train_labels, c='b', label='Training_data')\n",
    "    plt.scatter(test_data, test_labels, c='g', label=\"testing data\")\n",
    "    plt.scatter(test_data, predictions, c='r', label='predictions')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbc59e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b62fb9",
   "metadata": {},
   "source": [
    "### evaluating our model predictions with regression evalutation metrics\n",
    "\n",
    "\n",
    "##### depending on the problem you are working on, there will be different evaluation metrics to evaluate ur model preformance\n",
    "\n",
    "\n",
    "##### since you are working on regression, two main metrics: \n",
    "    ##### MAE - Mean absolute error, 'on average, how wrong is each of my model predictions'\n",
    "    ##### MSE - Mean square error, ' square the avg errors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "755b6a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 13.3574 - mae: 13.3574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.357446670532227, 13.357446670532227]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the test\n",
    "\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cad6ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([10.675481, 10.      , 10.18984 , 11.245001, 13.165477, 15.951269,\n",
       "       19.602386, 23.765701, 27.929005, 32.09229 ], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal the MAE\n",
    "\n",
    "mae= tf.metrics.mean_absolute_error(y_true= Y_test, \n",
    "                                    y_pred=Y_pred)\n",
    "\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8cf0434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([10.675481, 10.      , 10.18984 , 11.245001, 13.165477, 15.951269,\n",
       "       19.602386, 23.765701, 27.929005, 32.09229 ], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal the MAE and convert to tensor format\n",
    "\n",
    "mae= tf.metrics.mean_absolute_error(y_true= Y_test, \n",
    "                                    y_pred=tf.constant(Y_pred))\n",
    "\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a75d612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 72.6226  ],\n",
       "       [ 76.785904],\n",
       "       [ 80.9492  ],\n",
       "       [ 85.1125  ],\n",
       "       [ 89.275795],\n",
       "       [ 93.43909 ],\n",
       "       [ 97.60239 ],\n",
       "       [101.7657  ],\n",
       "       [105.929   ],\n",
       "       [110.09229 ]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28b19c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 72.6226  ],\n",
       "       [ 76.785904],\n",
       "       [ 80.9492  ],\n",
       "       [ 85.1125  ],\n",
       "       [ 89.275795],\n",
       "       [ 93.43909 ],\n",
       "       [ 97.60239 ],\n",
       "       [101.7657  ],\n",
       "       [105.929   ],\n",
       "       [110.09229 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "660543d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fcc853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 72.6226  ,  76.785904,  80.9492  ,  85.1125  ,  89.275795,\n",
       "        93.43909 ,  97.60239 , 101.7657  , 105.929   , 110.09229 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2dd90584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.357447>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal the MAE \n",
    "\n",
    "mae= tf.metrics.mean_absolute_error(y_true= Y_test, \n",
    "                                    y_pred=tf.squeeze(Y_pred))\n",
    "\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3fc9256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=178.64139>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal the MSE\n",
    "\n",
    "mse= tf.metrics.mean_squared_error(y_true= Y_test, \n",
    "                                    y_pred=tf.squeeze(Y_pred))\n",
    "\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb178e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some functions to reuse MAE and MSE\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true,\n",
    "                                         y_pred=tf.squeeze(y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_true,\n",
    "                                         y_pred=tf.squeeze(y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943deb40",
   "metadata": {},
   "source": [
    "### Running experiments to improve our model\n",
    "\n",
    "\n",
    "\n",
    "####  1. get more data - get more examples for ur model to train on\n",
    "\n",
    "#### 2.  make your model larger = this might come in the form of more layers or more hidden units in each layer.\n",
    "\n",
    "#### 3. Train for longer = give your model more of a chance to find patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2e41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43d70a15",
   "metadata": {},
   "source": [
    "#### lets do 3 modelling experiments\n",
    "\n",
    "\n",
    "##### 1. model_1  :  same as the original model, 1 layer, trained for 100 epochs\n",
    "\n",
    "#### 2. model_2   :  2 layers, trained for 100 epochs\n",
    "\n",
    "#### 3. model_3  :  2 layers, trained for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4ddbd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49c07f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 988us/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 787us/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 699us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 509us/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 994us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.7717 - mae: 8.771 - 0s 519us/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 991us/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 665us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 947us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.1615 - mae: 22.161 - 0s 1ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 868us/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0d957d90>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build Model_1    ::;  model_1 : same as the original model, 1 layer, trained for 100 epochs\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 1. create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. complile the model\n",
    "model_1.compile(loss= tf.keras.losses.mae,\n",
    "              optimizer= tf.keras.optimizers.SGD(),\n",
    "              metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model_1.fit(X_train,Y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d0d29ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0EBDB160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make and plot prediction for model_1\n",
    "\n",
    "\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "\n",
    "plot_predictions(predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ad89d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.745328>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=78.666824>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the model_1 evaluation metrics\n",
    "\n",
    "mae_1 = mae(Y_test, y_preds_1)\n",
    "\n",
    "mse_1= mse(Y_test, y_preds_1)\n",
    "\n",
    "\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "108541bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[53.57109 ],\n",
       "       [57.05633 ],\n",
       "       [60.541573],\n",
       "       [64.02681 ],\n",
       "       [67.512054],\n",
       "       [70.99729 ],\n",
       "       [74.48254 ],\n",
       "       [77.96777 ],\n",
       "       [81.45301 ],\n",
       "       [84.938255]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ac799c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 73.0019 - mae: 73.0019\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.5325 - mae: 17.5325\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 952us/step - loss: 20.4862 - mae: 20.4862\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.1871 - mae: 13.1871\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 980us/step - loss: 14.5492 - mae: 14.5492\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6087 - mae: 11.6087\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6668 - mae: 12.6668\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0468 - mae: 11.0468\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 39.7317 - mae: 39.7317\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.2189 - mae: 27.2189\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0353 - mae: 11.0353\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.4166 - mae: 24.4166\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.3019 - mae: 19.3019\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.5364 - mae: 23.5364\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 906us/step - loss: 15.3061 - mae: 15.3061\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.3811 - mae: 11.3811\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.2584 - mae: 23.2584\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.8111 - mae: 11.8111\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5386 - mae: 16.5386\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2427 - mae: 8.2427\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.4055 - mae: 14.4055\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.8167 - mae: 12.8167\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.4582 - mae: 15.4582\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 850us/step - loss: 15.2467 - mae: 15.2467\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.3296 - mae: 14.3296\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 874us/step - loss: 19.3209 - mae: 19.3209\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 992us/step - loss: 11.4720 - mae: 11.4720\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.1772 - mae: 29.1772\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2578 - mae: 9.2578\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 990us/step - loss: 29.8922 - mae: 29.8922\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 54.2504 - mae: 54.2504\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5899 - mae: 9.5899\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 969us/step - loss: 12.1833 - mae: 12.1833\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.9573 - mae: 23.9573\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6202 - mae: 12.6202\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.5189 - mae: 21.5189\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 687us/step - loss: 11.3948 - mae: 11.3948\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.4825 - mae: 13.4825\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8031 - mae: 10.8031\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.6186 - mae: 16.6186\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9878 - mae: 10.9878\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3120 - mae: 9.3120\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.6002 - mae: 9.6002\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.0120 - mae: 28.0120\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.2956 - mae: 11.2956\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.0830 - mae: 14.0830\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.5011 - mae: 13.5011\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 967us/step - loss: 17.3373 - mae: 17.3373\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7154 - mae: 13.7154\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.5670 - mae: 11.5670\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.2257 - mae: 30.2257\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7352 - mae: 13.7352\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 26.4457 - mae: 26.4457\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 26.0367 - mae: 26.0367\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2460 - mae: 11.2460\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2249 - mae: 13.2249\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8754 - mae: 9.8754\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.4150 - mae: 13.4150\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9405 - mae: 10.9405\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.5630 - mae: 13.5630\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.8775 - mae: 17.8775\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.7416 - mae: 8.7416\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.1381 - mae: 16.1381\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7498 - mae: 10.7498\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.1831 - mae: 22.1831\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2709 - mae: 10.2709\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4682 - mae: 13.4682\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.4343 - mae: 11.4343\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.6187 - mae: 13.6187\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6233 - mae: 15.6233\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8532 - mae: 11.8532\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6254 - mae: 16.6254\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.1342 - mae: 24.1342\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.6315 - mae: 9.6315\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4825 - mae: 12.4825\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.7086 - mae: 16.7086\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0873 - mae: 9.0873\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.0255 - mae: 24.0255\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.8174 - mae: 26.8174\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.7213 - mae: 11.7213\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.0124 - mae: 12.0124\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4085 - mae: 17.4085\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 764us/step - loss: 7.2769 - mae: 7.2769\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9605 - mae: 14.9605\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.2848 - mae: 15.2848\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.0979 - mae: 19.0979\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.8574 - mae: 29.8574\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1967 - mae: 10.1967\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.5458 - mae: 21.5458\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.5927 - mae: 10.5927\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.4135 - mae: 18.4135\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.4299 - mae: 7.4299\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.7470 - mae: 17.7470\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1306 - mae: 11.1306\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.4420 - mae: 19.4420\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.1735 - mae: 12.1735\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.5784 - mae: 11.5784\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8853 - mae: 13.8853\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.2151 - mae: 20.2151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0ec720a0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model_2   ;;;;   model_2 : 2 layers, trained for 100 epochs\n",
    "\n",
    "\n",
    "# 1. create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    #tf.keras.layers.Dense(100, activation = None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. complile the model\n",
    "model_2.compile(loss= tf.keras.losses.mae,\n",
    "              optimizer= tf.keras.optimizers.SGD(),\n",
    "              metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model_2.fit(X_train,Y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2ac0e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0EC99940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make and plot prediction for model_2\n",
    "\n",
    "\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "\n",
    "plot_predictions(predictions=y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05476580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=13.111005>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=174.71724>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the model_2 evaluation metrics\n",
    "\n",
    "mae_2 = mae(Y_test, y_preds_2)\n",
    "\n",
    "mse_2= mse(Y_test, y_preds_2)\n",
    "\n",
    "\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "820a840b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.9353 - mae: 21.9353\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.0862 - mae: 22.0862\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.3525 - mae: 28.3525\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.1307 - mae: 23.1307\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8184 - mae: 13.8184\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0722 - mae: 11.0722\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.0519 - mae: 12.0519\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8345 - mae: 10.8345\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 37.3929 - mae: 37.3929\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.0762 - mae: 25.0762\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2397 - mae: 10.2397\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.4130 - mae: 25.4130\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.7518 - mae: 16.7518\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.4925 - mae: 25.4925\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4063 - mae: 17.4063\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9920 - mae: 9.9920\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4421 - mae: 18.4421\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.3144 - mae: 11.3144\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.8716 - mae: 13.8716\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1646 - mae: 11.1646\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.1884 - mae: 17.1884\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4261 - mae: 15.4261\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.2387 - mae: 9.2387\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.2938 - mae: 17.2938\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.9566 - mae: 15.9566\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.9786 - mae: 20.9786\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.8546 - mae: 25.8546\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3662 - mae: 18.3662\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.2329 - mae: 9.2329\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.9805 - mae: 28.9805\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 52.4765 - mae: 52.4765\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 990us/step - loss: 11.8777 - mae: 11.8777\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.4465 - mae: 15.4465\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 955us/step - loss: 12.5576 - mae: 12.5576\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1757 - mae: 9.1757\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.4221 - mae: 16.4221\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 912us/step - loss: 11.0940 - mae: 11.0940\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.2250 - mae: 18.2250\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.1549 - mae: 19.1549\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 931us/step - loss: 20.5317 - mae: 20.5317\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.7742 - mae: 14.7742\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.1779 - mae: 12.1779\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6799 - mae: 10.6799\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 32.2250 - mae: 32.2250\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4480 - mae: 12.4480\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 983us/step - loss: 17.4835 - mae: 17.4835\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.7628 - mae: 15.7628\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3758 - mae: 8.3758\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.9879 - mae: 13.9879\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 793us/step - loss: 12.8303 - mae: 12.8303\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.8378 - mae: 14.8378\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.7219 - mae: 18.7219\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.1752 - mae: 24.1752\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.1613 - mae: 23.1613\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.0097 - mae: 24.0097\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1460 - mae: 11.1460\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.0999 - mae: 13.0999\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7993 - mae: 9.7993\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.2909 - mae: 13.2909\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 974us/step - loss: 10.8583 - mae: 10.8583\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 13.4608 - mae: 13.4608\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 17.4913 - mae: 17.4913\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 518us/step - loss: 9.1507 - mae: 9.1507\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3653 - mae: 18.3653\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 738us/step - loss: 10.1067 - mae: 10.1067\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.2312 - mae: 24.2312\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.8745 - mae: 10.8745\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 10.7588 - mae: 10.7588\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.2247 - mae: 23.2247\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.8148 - mae: 8.8148\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 598us/step - loss: 15.9842 - mae: 15.9842\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1389 - mae: 8.1389\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 962us/step - loss: 9.4628 - mae: 9.4628\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 28.1605 - mae: 28.1605\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.1856 - mae: 10.1856\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.1352 - mae: 13.1352\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3781 - mae: 18.3781\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0070 - mae: 9.0070\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 519us/step - loss: 23.4318 - mae: 23.4318\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.1007 - mae: 26.1007\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.3773 - mae: 11.3773\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 976us/step - loss: 12.4943 - mae: 12.4943\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.1806 - mae: 17.1806\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5868 - mae: 6.5868\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.2937 - mae: 20.2937\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 782us/step - loss: 10.1603 - mae: 10.1603\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.3412 - mae: 24.3412\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.0062 - mae: 19.0062\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.1568 - mae: 7.1568\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.2525 - mae: 18.2525\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.3016 - mae: 13.3016\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.8493 - mae: 14.8493\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.6420 - mae: 11.6420\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.1989 - mae: 16.1989\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.5408 - mae: 15.5408\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0745 - mae: 15.0745\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9028 - mae: 10.9028\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.3632 - mae: 14.3632\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 13.3803 - mae: 13.3803\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 953us/step - loss: 20.0006 - mae: 20.0006\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.5093 - mae: 22.5093\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2684 - mae: 11.2684\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3537 - mae: 9.3537\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.1414 - mae: 25.1414\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4051 - mae: 12.4051\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.3900 - mae: 9.3900\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.1575 - mae: 23.1575\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2658 - mae: 8.2658\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.9986 - mae: 13.9986\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6380 - mae: 10.6380\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9615 - mae: 16.9615\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2612 - mae: 8.2612\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.6433 - mae: 19.6433\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.3525 - mae: 17.3525\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2152 - mae: 11.2152\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5090 - mae: 23.5090\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7123 - mae: 9.7123\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7899 - mae: 10.7899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0862 - mae: 8.0862\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.8441 - mae: 29.8441\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.1167 - mae: 8.1167\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 987us/step - loss: 28.4188 - mae: 28.4188\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.0344 - mae: 33.0344\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.7398 - mae: 19.7398\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0483 - mae: 7.0483\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.8956 - mae: 21.8956\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 8.0288 - mae: 8.0288\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 988us/step - loss: 21.1270 - mae: 21.1270\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0605 - mae: 9.0605\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.1044 - mae: 24.1044\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.8044 - mae: 9.8044\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.3432 - mae: 18.3432\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6218 - mae: 7.6218\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.6010 - mae: 18.6010\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.5756 - mae: 10.5756\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 957us/step - loss: 18.2770 - mae: 18.2770\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 23.1654 - mae: 23.1654\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.1616 - mae: 9.1616\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 515us/step - loss: 8.9421 - mae: 8.9421\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.4477 - mae: 16.4477\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4558 - mae: 8.4558\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36.8323 - mae: 36.8323\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.5072 - mae: 25.5072\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5716 - mae: 9.5716\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.6433 - mae: 26.6433\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 972us/step - loss: 8.7122 - mae: 8.7122\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.6727 - mae: 15.6727\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3720 - mae: 18.3720\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.1830 - mae: 8.1830\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 512us/step - loss: 7.5115 - mae: 7.5115\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.2000 - mae: 18.2000\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2853 - mae: 10.2853\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.3987 - mae: 29.3987\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6230 - mae: 10.6230\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5145 - mae: 15.5145\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.1399 - mae: 17.1399\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 32.5115 - mae: 32.5115\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.6486 - mae: 10.6486\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 8.8944 - mae: 8.8944\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 992us/step - loss: 21.8907 - mae: 21.8907\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 969us/step - loss: 11.1114 - mae: 11.1114\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.4158 - mae: 21.4158\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.8954 - mae: 18.8954\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.7258 - mae: 12.7258\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.8948 - mae: 18.8948\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.8457 - mae: 26.8457\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0009 - mae: 10.0009\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.0898 - mae: 23.0898\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0868 - mae: 10.0868\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.8336 - mae: 17.8336\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.3574 - mae: 29.3574\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9520 - mae: 16.9520\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1855 - mae: 11.1855\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 27.4547 - mae: 27.4547\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4489 - mae: 8.4489\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4056 - mae: 9.4056\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.5519 - mae: 18.5519\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4275 - mae: 10.4275\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0056 - mae: 8.0056\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7260 - mae: 17.7260\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 11.1923 - mae: 11.1923\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 951us/step - loss: 12.3743 - mae: 12.3743\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 946us/step - loss: 27.2881 - mae: 27.2881\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5876 - mae: 7.5876\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9848 - mae: 15.9848\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.6030 - mae: 8.6030\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.7597 - mae: 28.7597\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.1783 - mae: 13.1783\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 18.3223 - mae: 18.3223\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7529 - mae: 13.7529\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7311 - mae: 13.7311\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.5937 - mae: 28.5937\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.0936 - mae: 7.0936\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0888 - mae: 7.0888\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 22.0412 - mae: 22.0412\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.7798 - mae: 20.7798\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4450 - mae: 12.4450\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8517 - mae: 17.8517\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6976 - mae: 13.6976\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.5117 - mae: 5.5117\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6463 - mae: 13.6463\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4264 - mae: 9.4264\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8496 - mae: 20.8496\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5375 - mae: 9.5375\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1761 - mae: 11.1761\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.7283 - mae: 17.7283\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.4239 - mae: 14.4239\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.7506 - mae: 16.7506\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.2737 - mae: 18.2737\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 975us/step - loss: 9.9818 - mae: 9.9818\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 979us/step - loss: 18.7556 - mae: 18.7556\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9413 - mae: 14.9413\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 817us/step - loss: 14.5283 - mae: 14.5283\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.1686 - mae: 23.1686\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 600us/step - loss: 13.6047 - mae: 13.6047\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0734 - mae: 10.0734\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4186 - mae: 12.4186\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 518us/step - loss: 5.8714 - mae: 5.8714\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.2063 - mae: 10.2063\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.8825 - mae: 28.8825\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.0701 - mae: 28.0701\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0777 - mae: 10.0777\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.6278 - mae: 14.6278\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.6448 - mae: 16.6448\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8666 - mae: 15.8666\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.0852 - mae: 16.0852\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8641 - mae: 13.8641\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9840 - mae: 17.9840\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.5783 - mae: 15.5783\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.1014 - mae: 21.1014\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.5060 - mae: 25.5060\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.5073 - mae: 16.5073\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3624 - mae: 7.3624\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.1462 - mae: 17.1462\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 586us/step - loss: 7.2218 - mae: 7.2218\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.3194 - mae: 9.3194\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1775 - mae: 8.1775\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.1610 - mae: 17.1610\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.9479 - mae: 8.9479\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.2574 - mae: 13.2574\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.8585 - mae: 8.8585\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 854us/step - loss: 18.8868 - mae: 18.8868\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.0563 - mae: 14.0563\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 960us/step - loss: 14.6840 - mae: 14.6840\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8171 - mae: 15.8171\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 963us/step - loss: 17.6968 - mae: 17.6968\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2535 - mae: 13.2535\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 974us/step - loss: 14.5275 - mae: 14.5275\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.2527 - mae: 23.2527\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3337 - mae: 9.3337\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 36.5867 - mae: 36.5867\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.7806 - mae: 21.7806\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3169 - mae: 7.3169\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.6447 - mae: 24.6447\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4179 - mae: 12.4179\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5846 - mae: 10.5846\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.1860 - mae: 14.1860\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2612 - mae: 11.2612\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 31.5570 - mae: 31.5570\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1806 - mae: 11.1806\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0363 - mae: 10.0363\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 8.9539 - mae: 8.9539\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 978us/step - loss: 21.4497 - mae: 21.4497\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 957us/step - loss: 11.4696 - mae: 11.4696\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3109 - mae: 13.3109\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0960 - mae: 11.0960\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.1820 - mae: 19.1820\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 40.6321 - mae: 40.6321\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8939 - mae: 12.8939\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.7735 - mae: 14.7735\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.5239 - mae: 28.5239\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.3649 - mae: 7.3649\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.3646 - mae: 6.3646\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 36.8359 - mae: 36.8359\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2925 - mae: 8.2925\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 27.6667 - mae: 27.6667\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6925 - mae: 10.6925\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.1202 - mae: 16.1202\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.2550 - mae: 21.2550\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.7470 - mae: 23.7470\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.2580 - mae: 8.2580\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4443 - mae: 8.4443\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 26.5833 - mae: 26.5833\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.1990 - mae: 14.1990\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.2652 - mae: 5.2652\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8363 - mae: 20.8363\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 27.5655 - mae: 27.5655\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 10.4466 - mae: 10.4466\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3191 - mae: 16.3191\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 16.5101 - mae: 16.5101\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.4372 - mae: 7.4372\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 852us/step - loss: 16.5537 - mae: 16.5537\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.3454 - mae: 25.3454\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.5567 - mae: 14.5567\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 520us/step - loss: 4.6779 - mae: 4.6779\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 663us/step - loss: 7.2820 - mae: 7.2820\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.5894 - mae: 19.5894\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.6188 - mae: 6.6188\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.0367 - mae: 22.0367\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1308 - mae: 9.1308\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 989us/step - loss: 11.1834 - mae: 11.1834\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 9.3357 - mae: 9.3357\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 513us/step - loss: 23.6902 - mae: 23.6902\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.9213 - mae: 7.9213\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.7434 - mae: 23.7434\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.8868 - mae: 5.8868\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3286 - mae: 21.3286\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3994 - mae: 18.3994\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 4.4978 - mae: 4.4978\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 974us/step - loss: 6.5091 - mae: 6.5091\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 35.4382 - mae: 35.4382\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.9148 - mae: 28.9148\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1945 - mae: 11.1945\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.5547 - mae: 23.5547\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.4208 - mae: 14.4208\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.9661 - mae: 19.9661\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.9954 - mae: 7.9954\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 18.1037 - mae: 18.1037\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6353 - mae: 10.6353\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.0212 - mae: 7.0212\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6726 - mae: 8.6726\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3385 - mae: 18.3385\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 984us/step - loss: 6.3034 - mae: 6.3034\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.6095 - mae: 14.6095\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 929us/step - loss: 6.9862 - mae: 6.9862\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.6239 - mae: 17.6239\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.3733 - mae: 14.3733\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 959us/step - loss: 17.6845 - mae: 17.6845\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 6.7786 - mae: 6.7786\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.7463 - mae: 19.7463\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5487 - mae: 10.5487\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3442 - mae: 16.3442\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.7154 - mae: 9.7154\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.0544 - mae: 13.0544\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 974us/step - loss: 32.4919 - mae: 32.4919\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0362 - mae: 11.0362\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.9478 - mae: 19.9478\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 34.3321 - mae: 34.3321\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 979us/step - loss: 9.2796 - mae: 9.2796\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3006 - mae: 17.3006\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9113 - mae: 14.9113\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3158 - mae: 10.3158\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.9336 - mae: 9.9336\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 30.8990 - mae: 30.8990\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6250 - mae: 10.6250\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.5353 - mae: 25.5353\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 975us/step - loss: 13.3548 - mae: 13.3548\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0062 - mae: 13.0062\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.3883 - mae: 15.3883\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 979us/step - loss: 32.8591 - mae: 32.8591\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 14.0585 - mae: 14.0585\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 517us/step - loss: 17.7457 - mae: 17.7457\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.3277 - mae: 11.3277\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 26.7386 - mae: 26.7386\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1938 - mae: 10.1938\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.7789 - mae: 14.7789\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 14.6654 - mae: 14.6654\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.3236 - mae: 12.3236\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.3227 - mae: 20.3227\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.9378 - mae: 10.9378\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.8188 - mae: 6.8188\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.8776 - mae: 23.8776\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.6005 - mae: 29.6005\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 954us/step - loss: 8.3080 - mae: 8.3080\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 6.1020 - mae: 6.1020\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.7127 - mae: 34.7127\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.3756 - mae: 7.3756\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.1755 - mae: 9.1755\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.8641 - mae: 10.8641\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6410 - mae: 8.6410\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 992us/step - loss: 6.4582 - mae: 6.4582\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.4218 - mae: 23.4218\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.4537 - mae: 10.4537\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 898us/step - loss: 13.0513 - mae: 13.0513\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 867us/step - loss: 14.9367 - mae: 14.9367\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.8224 - mae: 14.8224\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 974us/step - loss: 16.2965 - mae: 16.2965\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.8895 - mae: 20.8895\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.3745 - mae: 33.3745\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1589 - mae: 8.1589\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 13.0057 - mae: 13.0057\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4480 - mae: 8.4480\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 977us/step - loss: 7.0604 - mae: 7.0604\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.9545 - mae: 10.9545\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.8100 - mae: 19.8100\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 931us/step - loss: 24.7596 - mae: 24.7596\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.6847 - mae: 8.6847\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 525us/step - loss: 5.9197 - mae: 5.9197\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.3429 - mae: 24.3429\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.9424 - mae: 5.9424\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.0986 - mae: 16.0986\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.4637 - mae: 6.4637\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.5466 - mae: 12.5466\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 930us/step - loss: 12.4190 - mae: 12.4190\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3305 - mae: 7.3305\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5898 - mae: 7.5898\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.3907 - mae: 20.3907\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.8798 - mae: 5.8798\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.5904 - mae: 24.5904\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2330 - mae: 13.2330\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.3559 - mae: 8.3559\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.2302 - mae: 10.2302\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 989us/step - loss: 10.0815 - mae: 10.0815\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.2633 - mae: 6.2633\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.4353 - mae: 19.4353\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2699 - mae: 10.2699\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 992us/step - loss: 20.8920 - mae: 20.8920\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.8533 - mae: 30.8533\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.3428 - mae: 9.3428\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9321 - mae: 14.9321\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 21.8482 - mae: 21.8482\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 12.4072 - mae: 12.4072\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.6135 - mae: 6.6135\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.7063 - mae: 12.7063\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.9449 - mae: 26.9449\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.0251 - mae: 12.0251\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.0729 - mae: 13.0729\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 894us/step - loss: 16.0353 - mae: 16.0353\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.0797 - mae: 25.0797\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 960us/step - loss: 16.5748 - mae: 16.5748\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.6843 - mae: 8.6843\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.8024 - mae: 24.8024\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5055 - mae: 16.5055\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.2266 - mae: 7.2266\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.6458 - mae: 20.6458\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.3986 - mae: 6.3986\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2137 - mae: 13.2137\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.9741 - mae: 10.9741\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.8502 - mae: 11.8502\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.4907 - mae: 8.4907\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.5577 - mae: 18.5577\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1399 - mae: 10.1399\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.6716 - mae: 30.6716\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 982us/step - loss: 11.1748 - mae: 11.1748\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 28.7722 - mae: 28.7722\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.0387 - mae: 8.0387\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8111 - mae: 12.8111\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 33.9087 - mae: 33.9087\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 15.4282 - mae: 15.4282\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 17.7708 - mae: 17.7708\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 761us/step - loss: 6.4168 - mae: 6.4168\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 991us/step - loss: 12.8951 - mae: 12.8951\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.5577 - mae: 5.5577\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6911 - mae: 9.6911\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.1375 - mae: 15.1375\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.3797 - mae: 22.3797\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6292 - mae: 13.6292\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 826us/step - loss: 11.7118 - mae: 11.7118\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.2425 - mae: 15.2425\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.0833 - mae: 17.0833\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 993us/step - loss: 45.3382 - mae: 45.3382\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.1022 - mae: 26.1022\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.7545 - mae: 22.7545\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0246 - mae: 8.0246\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.4082 - mae: 10.4082\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.0143 - mae: 15.0143\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.5696 - mae: 16.5696\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.8504 - mae: 26.8504\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4544 - mae: 12.4544\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4981 - mae: 12.4981\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3250 - mae: 13.3250\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.5628 - mae: 29.5628\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.4787 - mae: 3.4787\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.2241 - mae: 15.2241\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.8594 - mae: 20.8594\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.4365 - mae: 30.4365\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.0335 - mae: 11.0335\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7942 - mae: 12.7942\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 3.2505 - mae: 3.2505\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.7254 - mae: 16.7254\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4109 - mae: 13.4109\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.3054 - mae: 15.3054\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.7739 - mae: 11.7739\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4374 - mae: 16.4374\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8916 - mae: 13.8916\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 30.6912 - mae: 30.6912\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.6252 - mae: 8.6252\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7660 - mae: 10.7660\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.9336 - mae: 17.9336\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.8334 - mae: 15.8334\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.3522 - mae: 21.3522\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.2810 - mae: 25.2810\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.8773 - mae: 23.8773\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.7682 - mae: 5.7682\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.8748 - mae: 19.8748\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.0581 - mae: 14.0581\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 30.6372 - mae: 30.6372\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.9881 - mae: 11.9881\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 519us/step - loss: 12.7608 - mae: 12.7608\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 23.6628 - mae: 23.6628\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.4167 - mae: 20.4167\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 981us/step - loss: 4.9820 - mae: 4.9820\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.6966 - mae: 12.6966\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.4265 - mae: 13.4265\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 980us/step - loss: 12.7079 - mae: 12.7079\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.6841 - mae: 17.6841\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.4230 - mae: 23.4230\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.1590 - mae: 9.1590\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 14.3818 - mae: 14.3818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab0efbb220>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model_3   ;;;;   model_3: 2 layers, trained for 500 epochs\n",
    "\n",
    "\n",
    "# 1. create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    #tf.keras.layers.Dense(100, activation = None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# 2. complile the model\n",
    "model_3.compile(loss= tf.keras.losses.mae,\n",
    "              optimizer= tf.keras.optimizers.SGD(),\n",
    "              metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "model_3.fit(X_train,Y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d465d438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0EF29820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make and plot prediction for model_3\n",
    "\n",
    "\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5f7d961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=57.909565>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3437.8718>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the model_3 evaluation metrics\n",
    "\n",
    "mae_3 = mae(Y_test, y_preds_3)\n",
    "\n",
    "mse_3= mse(Y_test, y_preds_3)\n",
    "\n",
    "\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f073bc",
   "metadata": {},
   "source": [
    "#### Comparing the results of our experiments\n",
    "\n",
    "\n",
    "##### lets compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7c9e7aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>8.745328</td>\n",
       "      <td>78.666824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>13.111005</td>\n",
       "      <td>174.717239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>57.909565</td>\n",
       "      <td>3437.871826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1   8.745328    78.666824\n",
       "1  model_2  13.111005   174.717239\n",
       "2  model_3  57.909565  3437.871826"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets compare the model results using Pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model_results = [['model_1', mae_1.numpy(), mse_1.numpy()],\n",
    "                ['model_2', mae_2.numpy(), mse_2.numpy()],\n",
    "                ['model_3', mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns = ['model', 'mae', 'mse'])\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "919dde1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# looks Model 2 performed\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e162d",
   "metadata": {},
   "source": [
    "### tracking our experiments\n",
    "\n",
    "#### one habit in ML modelling is to track the results of your experiments. \n",
    "\n",
    "##### and when doing it can be tedious if you're running lots of experiments\n",
    "\n",
    "\n",
    "\n",
    "##### ther are tools to help us ! \n",
    "\n",
    "#### 1. *Resource: * :: as you build more models, you'll want to look into using:    ### * TensorBoard *  = a components of the tensorflow library\n",
    "    \n",
    "####  2. *Weights and Biases: * ::  a tool for tracking all kinds of ML experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954df3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06234884",
   "metadata": {},
   "source": [
    "## Saving our Model\n",
    "\n",
    "\n",
    "#### saving our models allow us to use them outside of Google colab or Jupyter such as in a web app or a mobile app\n",
    "\n",
    "\n",
    "\n",
    "### there are 2 main formats we can save our models:\n",
    "    ### 1. the SavedModel format\n",
    "    ### 2. The HDF5 format\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2ec6c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\e3015558\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\e3015558\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Best_Model_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# save model using the SavedModel format\n",
    "\n",
    "model_2.save('Best_Model_SavedModel_format')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "19247e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model using HDF5 format\n",
    "\n",
    "\n",
    "model_2.save('Best_Model_HDF5_format.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ca929",
   "metadata": {},
   "source": [
    "### Loading in a Saved Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a72e85b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load in a the SavedModel format\n",
    "\n",
    "\n",
    "loaded_SavedModel_Format = tf.keras.models.load_model('Best_Model_SavedModel_format')\n",
    "\n",
    "loaded_SavedModel_Format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83513ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f8da549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0F48F310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the model_2 pred with savedmodel format model predictions\n",
    "\n",
    "model_2_preds =  model_2.predict(X_test)\n",
    "loaded_SavedModel_Format_preds = loaded_SavedModel_Format.predict(X_test)\n",
    "model_2_preds == loaded_SavedModel_Format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cec42da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loaded in a model using the .h5 format\n",
    "\n",
    "\n",
    "loaded_h5_model = tf.keras.models.load_model('Best_Model_HDF5_format.h5')\n",
    "\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c818eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AB0F48FCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see model_2 pred with  hdf5 format pred\n",
    "\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d99d6c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_true = Y_test, y_pred= model_2_preds) == mae (y_true = Y_test, y_pred=loaded_SavedModel_Format_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c5731c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.48064 ,  75.06517 ,  79.6497  ,  84.23422 ,  88.81875 ,\n",
       "        93.40326 ,  97.987785, 102.57232 , 107.156845, 111.74137 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36479171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.48064 ,  75.06517 ,  79.6497  ,  84.23422 ,  88.81875 ,\n",
       "        93.40326 ,  97.987785, 102.57232 , 107.156845, 111.74137 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SavedModel_Format_preds.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72c6da",
   "metadata": {},
   "source": [
    "### Download a model from Google Colab\n",
    "\n",
    "\n",
    "##### from Google Colab ,  Go to 'files' and right click on the file and click 'download'\n",
    "\n",
    "###### or \n",
    "\n",
    "'''\n",
    "from google.colab import files \n",
    "\n",
    "files.download('<pathfile.h5>')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### save  a file from colab to google drive (requires mounting google drive)\n",
    "'''\n",
    "!cp /content/Best_Model_HDF5_format.h5 /content/drive/MyDrive/Tensorflow\n",
    "\n",
    "\n",
    "!ls /content/drive/MyDrive/Tensorflow\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e9e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b38ab4",
   "metadata": {},
   "source": [
    "## A Larger Example from Kaggle.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Medical Cost Personal Datasets  - Insurance Forecast by using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed8797",
   "metadata": {},
   "source": [
    "Context\n",
    "Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Content Columns\n",
    "\n",
    "`age: age of primary beneficiary\n",
    "\n",
    "`sex: insurance contractor gender, female, male\n",
    "\n",
    " bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "`objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "\n",
    "`children: Number of children covered by health insurance / Number of dependents\n",
    "\n",
    "`smoker: Smoking\n",
    "\n",
    "`region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "\n",
    "`charges: Individual medical costs billed by health insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cac4d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requrired libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5064278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the insurance dataset\n",
    "\n",
    "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2304d7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1f0d8e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       female\n",
       "1         male\n",
       "2         male\n",
       "3         male\n",
       "4         male\n",
       "         ...  \n",
       "1333      male\n",
       "1334    female\n",
       "1335    female\n",
       "1336    female\n",
       "1337    female\n",
       "Name: sex, Length: 1338, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98e97f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       yes\n",
       "1        no\n",
       "2        no\n",
       "3        no\n",
       "4        no\n",
       "       ... \n",
       "1333     no\n",
       "1334     no\n",
       "1335     no\n",
       "1336     no\n",
       "1337    yes\n",
       "Name: smoker, Length: 1338, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance['smoker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "630f8fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       19\n",
       "1       18\n",
       "2       28\n",
       "3       33\n",
       "4       32\n",
       "        ..\n",
       "1333    50\n",
       "1334    18\n",
       "1335    18\n",
       "1336    21\n",
       "1337    61\n",
       "Name: age, Length: 1338, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e901aaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try One-Hot encoding our dataframe so its all numbers\n",
    "\n",
    "insurance_one_hot= pd.get_dummies(insurance)\n",
    "\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20b3955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y values (features and labels)\n",
    "\n",
    "# dropping 'charges' column from input(X) and adding this column as an output (y)\n",
    "\n",
    "\n",
    "X = insurance_one_hot.drop(\"charges\", axis =1)\n",
    "\n",
    "y = insurance_one_hot['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ccbc7939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0      19  27.900         0           1         0          0           1   \n",
       "1      18  33.770         1           0         1          1           0   \n",
       "2      28  33.000         3           0         1          1           0   \n",
       "3      33  22.705         0           0         1          1           0   \n",
       "4      32  28.880         0           0         1          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1333   50  30.970         3           0         1          1           0   \n",
       "1334   18  31.920         0           1         0          1           0   \n",
       "1335   18  36.850         0           1         0          1           0   \n",
       "1336   21  25.800         0           1         0          1           0   \n",
       "1337   61  29.070         0           1         0          0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 0                 1  \n",
       "1                    0                 0                 1                 0  \n",
       "2                    0                 0                 1                 0  \n",
       "3                    0                 1                 0                 0  \n",
       "4                    0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1333                 0                 1                 0                 0  \n",
       "1334                 1                 0                 0                 0  \n",
       "1335                 0                 0                 1                 0  \n",
       "1336                 0                 0                 0                 1  \n",
       "1337                 0                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 11 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b05d9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16884.92400\n",
       "1        1725.55230\n",
       "2        4449.46200\n",
       "3       21984.47061\n",
       "4        3866.85520\n",
       "           ...     \n",
       "1333    10600.54830\n",
       "1334     2205.98080\n",
       "1335     1629.83350\n",
       "1336     2007.94500\n",
       "1337    29141.36030\n",
       "Name: charges, Length: 1338, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view Y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16cbb2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Training and Test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    # train test split 80:20 \n",
    "\n",
    "len(X), len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be4ea162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>46</td>\n",
       "      <td>19.950</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47</td>\n",
       "      <td>24.320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>52</td>\n",
       "      <td>24.860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>39</td>\n",
       "      <td>34.320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>54</td>\n",
       "      <td>21.470</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>18</td>\n",
       "      <td>31.350</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>39</td>\n",
       "      <td>23.870</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>58</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>37</td>\n",
       "      <td>47.600</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>55</td>\n",
       "      <td>29.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "560    46  19.950         2           1         0          1           0   \n",
       "1285   47  24.320         0           1         0          1           0   \n",
       "1142   52  24.860         0           1         0          1           0   \n",
       "969    39  34.320         5           1         0          1           0   \n",
       "486    54  21.470         3           1         0          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1095   18  31.350         4           1         0          1           0   \n",
       "1130   39  23.870         5           1         0          1           0   \n",
       "1294   58  25.175         0           0         1          1           0   \n",
       "860    37  47.600         2           1         0          0           1   \n",
       "1126   55  29.900         0           0         1          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "560                  0                 1                 0                 0  \n",
       "1285                 1                 0                 0                 0  \n",
       "1142                 0                 0                 1                 0  \n",
       "969                  0                 0                 1                 0  \n",
       "486                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1095                 1                 0                 0                 0  \n",
       "1130                 0                 0                 1                 0  \n",
       "1294                 1                 0                 0                 0  \n",
       "860                  0                 0                 0                 1  \n",
       "1126                 0                 0                 0                 1  \n",
       "\n",
       "[1070 rows x 11 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b496091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>45</td>\n",
       "      <td>25.175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>36</td>\n",
       "      <td>30.020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>64</td>\n",
       "      <td>26.885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>46</td>\n",
       "      <td>25.745</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>19</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>63</td>\n",
       "      <td>35.090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>58</td>\n",
       "      <td>27.170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>38</td>\n",
       "      <td>28.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>54</td>\n",
       "      <td>47.410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>51</td>\n",
       "      <td>34.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "764    45  25.175         2           1         0          1           0   \n",
       "887    36  30.020         0           1         0          1           0   \n",
       "890    64  26.885         0           1         0          0           1   \n",
       "1293   46  25.745         3           0         1          1           0   \n",
       "259    19  31.920         0           0         1          0           1   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "109    63  35.090         0           0         1          0           1   \n",
       "575    58  27.170         0           1         0          1           0   \n",
       "535    38  28.025         1           0         1          1           0   \n",
       "543    54  47.410         0           1         0          0           1   \n",
       "846    51  34.200         1           1         0          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "764                  1                 0                 0                 0  \n",
       "887                  0                 1                 0                 0  \n",
       "890                  0                 1                 0                 0  \n",
       "1293                 0                 1                 0                 0  \n",
       "259                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "109                  0                 0                 1                 0  \n",
       "575                  0                 1                 0                 0  \n",
       "535                  1                 0                 0                 0  \n",
       "543                  0                 0                 1                 0  \n",
       "846                  0                 0                 0                 1  \n",
       "\n",
       "[268 rows x 11 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee364075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 630us/step - loss: 8637.0996 - mae: 8637.0996\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 7886.7759 - mae: 7886.7759\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 850us/step - loss: 7558.1470 - mae: 7558.1470\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7792.0220 - mae: 7792.0220\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 910us/step - loss: 7748.3892 - mae: 7748.3892\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 952us/step - loss: 7595.3940 - mae: 7595.3940\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 920us/step - loss: 7589.9849 - mae: 7589.9849\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 999us/step - loss: 7698.5586 - mae: 7698.5586\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7496.7778 - mae: 7496.7778\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 955us/step - loss: 7493.1733 - mae: 7493.1733\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 852us/step - loss: 7769.7314 - mae: 7769.7314\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 890us/step - loss: 7706.9033 - mae: 7706.9033\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 918us/step - loss: 7393.5322 - mae: 7393.5322\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: 7780.6982 - mae: 7780.6982\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 996us/step - loss: 7578.5093 - mae: 7578.5093\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 936us/step - loss: 7750.8350 - mae: 7750.8350\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 800us/step - loss: 7739.2134 - mae: 7739.2134\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 791us/step - loss: 7875.0635 - mae: 7875.0635\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7466.6768 - mae: 7466.6768\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 733us/step - loss: 7941.2310 - mae: 7941.2310\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 7640.2725 - mae: 7640.2725\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7539.2656 - mae: 7539.2656\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 797us/step - loss: 7619.9653 - mae: 7619.9653\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 791us/step - loss: 7644.1709 - mae: 7644.1709\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 769us/step - loss: 7709.0361 - mae: 7709.0361\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7366.8657 - mae: 7366.8657\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 793us/step - loss: 7444.3135 - mae: 7444.3135\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 763us/step - loss: 7616.4087 - mae: 7616.4087\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 746us/step - loss: 7686.3862 - mae: 7686.3862\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 850us/step - loss: 7548.0981 - mae: 7548.0981\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 884us/step - loss: 7501.5532 - mae: 7501.5532\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7363.4155 - mae: 7363.4155\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 6331.7734 - mae: 6331.773 - 0s 853us/step - loss: 7295.4468 - mae: 7295.4468\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 794us/step - loss: 7569.8813 - mae: 7569.8813\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: 7548.2002 - mae: 7548.2002\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 732us/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7529.7739 - mae: 7529.7739\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 849us/step - loss: 7467.3232 - mae: 7467.3232\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7635.9282 - mae: 7635.9282\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 838us/step - loss: 7536.8403 - mae: 7536.8403\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 7616.5845 - mae: 7616.5845\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 7439.4932 - mae: 7439.4932\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 7321.8423 - mae: 7321.842 - 0s 825us/step - loss: 7538.0151 - mae: 7538.0151\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 996us/step - loss: 7415.1460 - mae: 7415.1460\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 763us/step - loss: 7420.6938 - mae: 7420.6938\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 764us/step - loss: 7509.9829 - mae: 7509.9829\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 763us/step - loss: 7541.1123 - mae: 7541.1123\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 698us/step - loss: 7467.8633 - mae: 7467.8633\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 735us/step - loss: 7389.3545 - mae: 7389.3545\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 809us/step - loss: 7499.7749 - mae: 7499.7749\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 689us/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 756us/step - loss: 7429.5859 - mae: 7429.5859\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 676us/step - loss: 7313.4014 - mae: 7313.4014\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 733us/step - loss: 7526.3887 - mae: 7526.3887\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 822us/step - loss: 7542.2661 - mae: 7542.2661\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 793us/step - loss: 7576.9277 - mae: 7576.9277\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 703us/step - loss: 7546.4058 - mae: 7546.4058\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 557us/step - loss: 7351.2261 - mae: 7351.2261\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 579us/step - loss: 7302.1436 - mae: 7302.1436\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 644us/step - loss: 7393.0879 - mae: 7393.0879\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 762us/step - loss: 7442.2881 - mae: 7442.2881\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 6876.6304 - mae: 6876.630 - 0s 722us/step - loss: 7492.6782 - mae: 7492.6782\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 765us/step - loss: 7561.9165 - mae: 7561.9165\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7340.5142 - mae: 7340.5142\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 620us/step - loss: 7496.0854 - mae: 7496.0854\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 601us/step - loss: 7617.0298 - mae: 7617.0298\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 585us/step - loss: 7641.1948 - mae: 7641.1948\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 674us/step - loss: 7084.2744 - mae: 7084.2744\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 852us/step - loss: 7240.4907 - mae: 7240.4907\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 692us/step - loss: 7283.4888 - mae: 7283.4888\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 647us/step - loss: 7335.5063 - mae: 7335.5063\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 702us/step - loss: 7275.6392 - mae: 7275.6392\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 782us/step - loss: 7313.1855 - mae: 7313.1855\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 681us/step - loss: 7485.7578 - mae: 7485.7578\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7352.2798 - mae: 7352.2798\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 7520.5703 - mae: 7520.5703\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7279.3779 - mae: 7279.3779\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 7273.8477 - mae: 7273.8477\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 988us/step - loss: 7176.5210 - mae: 7176.5210\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7425.6294 - mae: 7425.6294\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7403.1289 - mae: 7403.1289\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7356.0088 - mae: 7356.0088\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7484.7271 - mae: 7484.7271\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 985us/step - loss: 7217.6079 - mae: 7217.6079\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: 7134.1558 - mae: 7134.1558\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: 7083.4351 - mae: 7083.4351\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 7268.7456 - mae: 7268.7456\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 923us/step - loss: 7470.5225 - mae: 7470.5225\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7210.9541 - mae: 7210.9541\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7395.6807 - mae: 7395.6807\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7328.0884 - mae: 7328.0884\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7230.4380 - mae: 7230.4380\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 912us/step - loss: 7261.3936 - mae: 7261.3936\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 873us/step - loss: 7342.5684 - mae: 7342.5684\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7106.1709 - mae: 7106.1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab110c2310>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a neural network (sort of like model_2 above)\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Create a model \n",
    "\n",
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Compile the model\n",
    "\n",
    "insurance_model.compile(loss= tf.keras.losses.mae,\n",
    "                          optimizer= tf.keras.optimizers.SGD(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "insurance_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f2f7095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0b4e845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560      9193.83850\n",
       "1285     8534.67180\n",
       "1142    27117.99378\n",
       "969      8596.82780\n",
       "486     12475.35130\n",
       "           ...     \n",
       "1095     4561.18850\n",
       "1130     8582.30230\n",
       "1294    11931.12525\n",
       "860     46113.51100\n",
       "1126    10214.63600\n",
       "Name: charges, Length: 1070, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8f54596d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364489)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median(), y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e3f5434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to try improve our model, we will run 2 experiments\\n\\n1. add an extra layer with more hidden units with different optimizers like SGD, ADAM , etc.. \\n2. same as above by Train for longer with 200 epochs\\n3. (you can do your own experiment)'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' lets try improving our model '''\n",
    "\n",
    "\n",
    "\n",
    "''' to try improve our model, we will run 2 experiments\n",
    "\n",
    "1. add an extra layer with more hidden units with different optimizers like SGD, ADAM , etc.. \n",
    "2. same as above by Train for longer with 200 epochs\n",
    "3. (you can do your own experiment)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb93df0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 792us/step - loss: nan - mae: nan        \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 938us/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 925us/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 891us/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 860us/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 702us/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - ETA: 0s - loss: nan - mae: na - 0s 676us/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 760us/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 874us/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 852us/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 908us/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 996us/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 920us/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 938us/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 849us/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 945us/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 822us/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 937us/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 941us/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 819us/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 846us/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 879us/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 869us/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 935us/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 763us/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 825us/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 849us/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 901us/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - ETA: 0s - loss: nan - mae: na - 0s 731us/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 733us/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 763us/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 698us/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 847us/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 793us/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 616us/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 675us/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 908us/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 879us/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 888us/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 908us/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 852us/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 782us/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 879us/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 849us/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 808us/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 892us/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab11380760>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra layer with more hidden units with SGD optimizer\n",
    "\n",
    "\n",
    "#  set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 1. create a model\n",
    "\n",
    "insurance_model_2_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "insurance_model_2_1.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.SGD(),\n",
    "                         metrics=['mae'])\n",
    "\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "\n",
    "insurance_model_2_1.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "094db669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 997us/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7528.8413 - mae: 7528.8413\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 937us/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 969us/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 967us/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 775us/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 970us/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 960us/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 7024.3506 - mae: 7024.3506\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 952us/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 989us/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 896us/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 875us/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 996us/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 911us/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 921us/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 896us/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 969us/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 998us/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6530.0439 - mae: 6530.0439\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 887us/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 972us/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 820us/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 970us/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 889us/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 937us/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 969us/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 837us/step - loss: 6337.6602 - mae: 6337.6602\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 850us/step - loss: 6310.1943 - mae: 6310.1943\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 852us/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 969us/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 861us/step - loss: 6148.8398 - mae: 6148.8398\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 878us/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6031.3843 - mae: 6031.3843\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5995.2178 - mae: 5995.2178\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5963.0723 - mae: 5963.0723\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5834.3071 - mae: 5834.3071\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 848us/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5711.3481 - mae: 5711.3481\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 946us/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 940us/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 955us/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 881us/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 999us/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 926us/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 856us/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5288.8164 - mae: 5288.8164\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 954us/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 878us/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 924us/step - loss: 5059.8643 - mae: 5059.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab115c3e80>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra layer with more hidden units with Adam optimizer since we are getting NaN in previous model\n",
    "\n",
    "\n",
    "#  set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 1. create a model\n",
    "\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                         optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=['mae'])\n",
    "\n",
    "\n",
    "\n",
    "# 3. fit the model\n",
    "\n",
    "# 3. fit the model\n",
    "\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "025ee404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 779us/step - loss: 4924.3477 - mae: 4924.3477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4924.34765625, 4924.34765625]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "529de254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense_37 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 938us/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 936us/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7528.8413 - mae: 7528.8413\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 999us/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 908us/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 854us/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 720us/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 7024.3506 - mae: 7024.3506\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 982us/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 10248.1953 - mae: 10248.195 - 0s 851us/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 910us/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 744us/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 940us/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 6618.1016 - mae: 6618.1016\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6530.0439 - mae: 6530.0439\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 911us/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 940us/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 5444.3989 - mae: 5444.398 - 0s 811us/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 881us/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 961us/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 841us/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 794us/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6337.6602 - mae: 6337.6602\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 940us/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6310.1943 - mae: 6310.1943\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 852us/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 743us/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 936us/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 852us/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 853us/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 825us/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 936us/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 852us/step - loss: 6148.8398 - mae: 6148.8398\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 793us/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 849us/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 794us/step - loss: 6031.3843 - mae: 6031.3843\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 854us/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 5995.2178 - mae: 5995.2178\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 838us/step - loss: 5963.0723 - mae: 5963.0723\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 791us/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 869us/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 991us/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 828us/step - loss: 5834.3071 - mae: 5834.3071\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 896us/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 847us/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5711.3481 - mae: 5711.3481\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 865us/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 810us/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 790us/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 1000us/step - loss: 5288.8164 - mae: 5288.8164\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 995us/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5059.8643 - mae: 5059.8643\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4987.6191 - mae: 4987.6191\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 4915.2905 - mae: 4915.2905\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 790us/step - loss: 4847.3604 - mae: 4847.3604\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 820us/step - loss: 4768.0151 - mae: 4768.0151\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 4683.4727 - mae: 4683.4727\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 967us/step - loss: 4600.5054 - mae: 4600.5054\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 910us/step - loss: 4513.1436 - mae: 4513.1436\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 4422.2983 - mae: 4422.2983\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4339.9595 - mae: 4339.9595\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4254.3916 - mae: 4254.3916\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4173.1797 - mae: 4173.1797\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4102.2939 - mae: 4102.2939\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 733us/step - loss: 4031.9590 - mae: 4031.9590\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3986.0220 - mae: 3986.0220\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 878us/step - loss: 3943.2346 - mae: 3943.2346\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 910us/step - loss: 3918.8979 - mae: 3918.8979\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3895.5610 - mae: 3895.5610\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3869.5676 - mae: 3869.5676\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3850.2136 - mae: 3850.2136\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3834.7346 - mae: 3834.7346\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3827.0952 - mae: 3827.0952\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 999us/step - loss: 3821.6382 - mae: 3821.6382\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3813.8315 - mae: 3813.8315\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 937us/step - loss: 3805.7305 - mae: 3805.7305\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 982us/step - loss: 3794.7087 - mae: 3794.7087\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 820us/step - loss: 3804.4949 - mae: 3804.4949\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3796.0596 - mae: 3796.0596\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 836us/step - loss: 3791.0417 - mae: 3791.0417\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 3800.0693 - mae: 3800.0693\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3788.5005 - mae: 3788.5005\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 779us/step - loss: 3780.8442 - mae: 3780.8442\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3774.5413 - mae: 3774.5413\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3771.0156 - mae: 3771.0156\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3769.3762 - mae: 3769.3762\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3766.7615 - mae: 3766.7615\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 936us/step - loss: 3765.5510 - mae: 3765.5510\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 749us/step - loss: 3774.5032 - mae: 3774.5032\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 911us/step - loss: 3785.3909 - mae: 3785.3909\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 822us/step - loss: 3761.1299 - mae: 3761.1299\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 790us/step - loss: 3764.1750 - mae: 3764.1750\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3763.9250 - mae: 3763.9250\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 788us/step - loss: 3762.7959 - mae: 3762.7959\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3754.4397 - mae: 3754.4397\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3750.3347 - mae: 3750.3347\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 837us/step - loss: 3750.4006 - mae: 3750.4006\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 704us/step - loss: 3755.4736 - mae: 3755.4736\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3750.3223 - mae: 3750.3223\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3758.1089 - mae: 3758.1089\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 906us/step - loss: 3743.4863 - mae: 3743.4863\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 882us/step - loss: 3738.5342 - mae: 3738.5342\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 983us/step - loss: 3740.1384 - mae: 3740.1384\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 846us/step - loss: 3742.4954 - mae: 3742.4954\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 970us/step - loss: 3744.4399 - mae: 3744.4399\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3737.1826 - mae: 3737.1826\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 999us/step - loss: 3737.6543 - mae: 3737.6543\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3737.1665 - mae: 3737.1665\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3733.1101 - mae: 3733.1101\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3729.5811 - mae: 3729.5811\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 764us/step - loss: 3725.9050 - mae: 3725.9050\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 791us/step - loss: 3733.2820 - mae: 3733.2820\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 853us/step - loss: 3728.2559 - mae: 3728.2559\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 825us/step - loss: 3724.5825 - mae: 3724.5825\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 879us/step - loss: 3723.0811 - mae: 3723.0811\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 995us/step - loss: 3726.9470 - mae: 3726.9470\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3716.5430 - mae: 3716.5430\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3721.9155 - mae: 3721.9155\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3721.1814 - mae: 3721.1814\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 3715.2458 - mae: 3715.2458\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 794us/step - loss: 3713.9756 - mae: 3713.9756\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 819us/step - loss: 3707.9919 - mae: 3707.9919\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3707.4160 - mae: 3707.4160\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3710.6831 - mae: 3710.6831\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 926us/step - loss: 3703.3616 - mae: 3703.3616\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3710.9385 - mae: 3710.9385\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 999us/step - loss: 3713.0413 - mae: 3713.0413\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3705.0571 - mae: 3705.0571\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 849us/step - loss: 3698.9333 - mae: 3698.9333\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3697.9985 - mae: 3697.9985\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3704.9150 - mae: 3704.9150\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 854us/step - loss: 3710.3682 - mae: 3710.3682\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 791us/step - loss: 3696.6482 - mae: 3696.6482\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3692.7339 - mae: 3692.7339\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 907us/step - loss: 3691.1653 - mae: 3691.1653\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 867us/step - loss: 3699.2437 - mae: 3699.2437\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3693.2483 - mae: 3693.2483\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 819us/step - loss: 3696.1389 - mae: 3696.1389\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 839us/step - loss: 3687.8640 - mae: 3687.8640\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3693.3562 - mae: 3693.3562\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 822us/step - loss: 3682.7324 - mae: 3682.7324\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 956us/step - loss: 3683.2891 - mae: 3683.2891\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 995us/step - loss: 3697.6533 - mae: 3697.6533\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3684.6660 - mae: 3684.6660\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 838us/step - loss: 3675.5154 - mae: 3675.5154\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 966us/step - loss: 3676.3921 - mae: 3676.3921\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 761us/step - loss: 3672.8452 - mae: 3672.8452\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3682.0281 - mae: 3682.0281\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3665.7961 - mae: 3665.7961\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 925us/step - loss: 3671.7419 - mae: 3671.7419\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 850us/step - loss: 3680.5464 - mae: 3680.5464\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 3665.6401 - mae: 3665.6401\n"
     ]
    }
   ],
   "source": [
    "# try the above model by adding 200 epochs\n",
    "\n",
    "\n",
    "# set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 1. create the model\n",
    "insurance_model_3= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "insurance_model_3.compile(loss= tf.keras.losses.mae,\n",
    "                         optimizer= tf.keras.optimizers.Adam(),\n",
    "                         metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3.  fit the model\n",
    "history= insurance_model_3.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "052a5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 3491.2961 - mae: 3491.2961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3491.296142578125, 3491.296142578125]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model3\n",
    "\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "06f26fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history (also known as a loss curve or a training curve)\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35544829",
   "metadata": {},
   "source": [
    "### Preprocessing the data  (Normalization and Standardization)\n",
    "\n",
    "\n",
    "\n",
    "#### in terms of scaling values, NN tend ot prefer Normalization.\n",
    "\n",
    "#### if you are not sure on which to use, you could try both and see which performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d95b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3897d18b",
   "metadata": {},
   "source": [
    "#### Steps in modelling with TensorFlow\n",
    "\n",
    "\n",
    "##### 1. Turn all data into numbers (NN cant handle strings)\n",
    "##### 2. Make sure all of your tensors are the right shape\n",
    "##### 3. Scale features (normalize or standardize, NN tend to perform normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7cd82be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['age'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "82ce852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAS3ElEQVR4nO3df5Bd9V3/8eeLH5aW1ikMC6ZJdLETfwBjQ91G58v3q5RWi6UaqkNNRzvRwaaOdGxHZzQwjuAfmeHrtFQdbTVYNNa2mEpbYqnagNVOZyphQSyEwJCRCNtkyLbVAfx2QNL394979vSa3N3cwN69J7vPx8zOPedzz+ecdz4EXpzPOXtOqgpJkgBOGXcBkqTuMBQkSS1DQZLUMhQkSS1DQZLUOm3cBbwY55xzTk1OTo67DEk6qdx7771fraqJQd+d1KEwOTnJ9PT0uMuQpJNKkn+f7zunjyRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJrZP6N5p18pjcesdYjnvgxivGclzpZOWZgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklojC4UkZyTZk+Rfk+xN8jtN+9lJdid5tPk8q6/PtUn2J3kkyZtGVZskabBRnik8C1xWVa8B1gOXJ/lhYCtwV1WtA+5q1klyAbAJuBC4HPhgklNHWJ8k6SgjC4XqeaZZPb35KWAjsKNp3wFc2SxvBG6tqmer6jFgP7BhVPVJko410msKSU5Ncj9wGNhdVXcD51XVIYDm89xm89XAE33dZ5q2o/e5Jcl0kunZ2dlRli9JK85IQ6GqjlTVemANsCHJRQtsnkG7GLDP7VU1VVVTExMTi1SpJAmW6O6jqvpP4B/pXSt4MskqgObzcLPZDLC2r9sa4OBS1CdJ6hnl3UcTSV7ZLL8UeCPwMLAL2Nxsthm4vVneBWxK8pIk5wPrgD2jqk+SdKxRvk9hFbCjuYPoFGBnVX0myZeAnUmuBh4HrgKoqr1JdgIPAc8D11TVkRHWJ0k6yshCoaq+DFw8oP1rwBvm6bMN2DaqmiRJC/M3miVJLUNBktTyHc1a1sb1bmjw/dA6OXmmIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpNbIQiHJ2iSfT7Ivyd4k72nab0jylST3Nz9v7utzbZL9SR5J8qZR1SZJGuy0Ee77eeDXq+q+JK8A7k2yu/nuA1X1vv6Nk1wAbAIuBF4F3Jnke6rqyAhrlCT1GdmZQlUdqqr7muWngX3A6gW6bARurapnq+oxYD+wYVT1SZKOtSTXFJJMAhcDdzdN707y5SS3JDmraVsNPNHXbYaFQ0SStMhGHgpJXg7cBry3qp4CPgS8GlgPHALeP7fpgO41YH9bkkwnmZ6dnR1N0ZK0Qo00FJKcTi8QPlpVnwSoqier6khVfRO4mW9NEc0Aa/u6rwEOHr3PqtpeVVNVNTUxMTHK8iVpxRnl3UcBPgzsq6qb+tpX9W32VuDBZnkXsCnJS5KcD6wD9oyqPknSsUZ599ElwDuAB5Lc37RdB7w9yXp6U0MHgHcBVNXeJDuBh+jduXSNdx5J0tIaWShU1RcZfJ3gswv02QZsG1VNkqSF+RvNkqSWoSBJahkKkqSWoSBJahkKkqTWKG9JVcdMbr1j3CVI6jjPFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQaWSgkWZvk80n2Jdmb5D1N+9lJdid5tPk8q6/PtUn2J3kkyZtGVZskabChQiHJRS9g388Dv15V3w/8MHBNkguArcBdVbUOuKtZp/luE3AhcDnwwSSnvoDjSpJeoGHPFP44yZ4kv5LklcN0qKpDVXVfs/w0sA9YDWwEdjSb7QCubJY3ArdW1bNV9RiwH9gwZH2SpEUwVChU1f8Gfg5YC0wn+ViSHxv2IEkmgYuBu4HzqupQs99DwLnNZquBJ/q6zTRtR+9rS5LpJNOzs7PDliBJGsLQ1xSq6lHgt4DfBH4U+IMkDyf56YX6JXk5cBvw3qp6aqFNBx12QB3bq2qqqqYmJiaGLV+SNIRhryn8QJIP0JsCugz4yeZawWXABxbodzq9QPhoVX2yaX4yyarm+1XA4aZ9ht6ZyJw1wMET+LNIkl6k04bc7g+Bm4Hrquobc41VdTDJbw3qkCTAh4F9VXVT31e7gM3Ajc3n7X3tH0tyE/AqYB2w5wT+LFKnTG69YyzHPXDjFWM5rpaHYUPhzcA3quoIQJJTgDOq6v9V1Ufm6XMJ8A7ggST3N23X0QuDnUmuBh4HrgKoqr1JdgIP0btz6Zq540mSlsawoXAn8EbgmWb9ZcDngP81X4eq+iKDrxMAvGGePtuAbUPWJElaZMNeaD6jquYCgWb5ZaMpSZI0LsOGwn8lee3cSpIfBL6xwPaSpJPQsNNH7wU+kWTubqBVwM+OpCJJ0tgMFQpVdU+S7wO+l951goer6r9HWpkkackNe6YA8DpgsulzcRKq6i9GUpUkaSyGCoUkHwFeDdwPzN0mWoChIEnLyLBnClPABVV1zGMnJEnLx7B3Hz0IfMcoC5Ekjd+wZwrnAA8l2QM8O9dYVT81kqokSWMxbCjcMMoiJEndMOwtqf+U5LuAdVV1Z5KXAb4VTZKWmWEfnf1O4K+BP2maVgOfHlFNkqQxGfZC8zX0nnr6FLQv3Dl3wR6SpJPOsKHwbFU9N7eS5DQGvBVNknRyGzYU/inJdcBLm3czfwL4m9GVJUkah2FDYSswCzwAvAv4LL33NUuSlpFh7z76Jr3Xcd482nIkSeM07LOPHmPANYSq+u5Fr0iSNDYn8uyjOWfQe6/y2YtfjiRpnIa6plBVX+v7+UpV/R5w2WhLkyQttWGnj17bt3oKvTOHV4ykIknS2Aw7ffT+vuXngQPA2xa9GknSWA1799HrR12IJGn8hp0++rWFvq+qmwb0uQV4C3C4qi5q2m4A3knvdx4ArquqzzbfXQtcTe/Nbr9aVX8/5J9BkrRITuTuo9cBu5r1nwS+ADyxQJ8/B/6QY1/Z+YGqel9/Q5ILgE3AhcCrgDuTfE9VHUGStGRO5CU7r62qp6H9P/5PVNUvzdehqr6QZHLI/W8Ebq2qZ4HHkuwHNgBfGrK/JGkRDPuYi+8Enutbfw6YfIHHfHeSLye5JclZTdtq/udZx0zTdowkW5JMJ5menZ0dtIkk6QUaNhQ+AuxJckOS64G7OXZaaBgfAl4NrAcO8a27mjJg24FPYa2q7VU1VVVTExMTL6AESdJ8hr37aFuSvwX+T9P0i1X1Lyd6sKp6cm45yc3AZ5rVGWBt36ZrgIMnun9J0osz7JkCwMuAp6rq94GZJOef6MGSrOpbfSvwYLO8C9iU5CXNftcBe050/5KkF2fYW1Kvp3cH0vcCfwacDvwlvbexzdfn48ClwDlJZoDrgUuTrKc3NXSA3mO4qaq9SXYCD9H75bhrvPNIkpbesHcfvRW4GLgPoKoOJlnwMRdV9fYBzR9eYPttwLYh65EkjcCw00fPVVXRXPxNcuboSpIkjcuwobAzyZ8Ar0zyTuBOfOGOJC07x50+ShLgr4DvA56id13ht6tq94hrkyQtseOGQlVVkk9X1Q8CBoEkLWPDTh/9c5LXjbQSSdLYDXv30euBX05yAPgver+BXFX1A6MqTJK09BYMhSTfWVWPAz+xRPVIksboeGcKn6b3dNR/T3JbVf3MEtQkSRqT411T6H9Q3XePshBJ0vgd70yh5lnWizC59Y5xlyBJAx0vFF6T5Cl6ZwwvbZbhWxeav32k1UmSltSCoVBVpy5VIZKk8TuRR2dLkpY5Q0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1BpZKCS5JcnhJA/2tZ2dZHeSR5vPs/q+uzbJ/iSPJHnTqOqSJM1vlGcKfw5cflTbVuCuqloH3NWsk+QCYBNwYdPng0l8QqskLbGRhUJVfQH4+lHNG4EdzfIO4Mq+9lur6tmqegzYD2wYVW2SpMGW+prCeVV1CKD5PLdpXw080bfdTNN2jCRbkkwnmZ6dnR1psZK00nTlQnMGtA18/WdVba+qqaqampiYGHFZkrSyHO91nIvtySSrqupQklXA4aZ9Bljbt90a4OAS1yYtC+N8B/iBG68Y27G1OJb6TGEXsLlZ3gzc3te+KclLkpwPrAP2LHFtkrTijexMIcnHgUuBc5LMANcDNwI7k1wNPA5cBVBVe5PsBB4Cngeuqaojo6pNkjTYyEKhqt4+z1dvmGf7bcC2UdUjSTq+rlxoliR1gKEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKk1mnjOGiSA8DTwBHg+aqaSnI28FfAJHAAeFtV/cc46pOklWqcZwqvr6r1VTXVrG8F7qqqdcBdzbokaQl1afpoI7CjWd4BXDm+UiRpZRpXKBTwuST3JtnStJ1XVYcAms9zB3VMsiXJdJLp2dnZJSpXklaGsVxTAC6pqoNJzgV2J3l42I5VtR3YDjA1NVWjKlCSVqKxnClU1cHm8zDwKWAD8GSSVQDN5+Fx1CZJK9mSh0KSM5O8Ym4Z+HHgQWAXsLnZbDNw+1LXJkkr3Timj84DPpVk7vgfq6q/S3IPsDPJ1cDjwFVjqE2SVrQlD4Wq+jfgNQPavwa8YanrkSR9S5duSZUkjZmhIElqGQqSpJahIElqGQqSpJahIElqjesxF5KWocmtd4zluAduvGIsx12OVnQojOsvsCR1ldNHkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJaq3ox1xIWh585tLi8UxBktQyFCRJLUNBktQyFCRJLUNBktTqXCgkuTzJI0n2J9k67nokaSXp1C2pSU4F/gj4MWAGuCfJrqp6aLyVSdKxxvn2xlHdDtu1M4UNwP6q+reqeg64Fdg45pokacXo1JkCsBp4om99Bvih/g2SbAG2NKvPJHlkgf2dA3x1UStcfNa4OLpeY9frA2tcLEtSY/7vi+r+XfN90bVQyIC2+h8rVduB7UPtLJmuqqnFKGxUrHFxdL3GrtcH1rhYToYaF9K16aMZYG3f+hrg4JhqkaQVp2uhcA+wLsn5Sb4N2ATsGnNNkrRidGr6qKqeT/Ju4O+BU4Fbqmrvi9jlUNNMY2aNi6PrNXa9PrDGxXIy1DivVNXxt5IkrQhdmz6SJI2RoSBJai2LUEhyS5LDSR7sa7shyVeS3N/8vHnMNa5N8vkk+5LsTfKepv3sJLuTPNp8ntXBGjszlknOSLInyb82Nf5O096lcZyvxs6MY1PPqUn+JclnmvXOjOECNXZqDJuaDiR5oKlnumnr3FgOa1lcU0jyI8AzwF9U1UVN2w3AM1X1vnHWNifJKmBVVd2X5BXAvcCVwC8AX6+qG5tnPZ1VVb/ZsRrfRkfGMkmAM6vqmSSnA18E3gP8NN0Zx/lqvJyOjCNAkl8DpoBvr6q3JPldOjKGC9R4Ax0aQ+iFAjBVVV/ta+vcWA5rWZwpVNUXgK+Pu46FVNWhqrqvWX4a2EfvN7g3AjuazXbQ+4/wWCxQY2dUzzPN6unNT9GtcZyvxs5Isga4AvjTvubOjCHMW+PJolNjeSKWRSgs4N1JvtxML3Xm9C3JJHAxcDdwXlUdgt5/lIFzx1ha66gaoUNj2Uwp3A8cBnZXVefGcZ4aoTvj+HvAbwDf7Gvr1BgyuEbozhjOKeBzSe5N7zE80L2xHNpyDoUPAa8G1gOHgPePtZpGkpcDtwHvraqnxl3PIANq7NRYVtWRqlpP7zfeNyS5aJz1DDJPjZ0YxyRvAQ5X1b3jOP4wFqixE2N4lEuq6rXATwDXNNPZJ61lGwpV9WTzL+Y3gZvpPYF1rJr55duAj1bVJ5vmJ5u5/Lk5/cPjqq+p4ZgauziWAFX1n8A/0pur79Q4zumvsUPjeAnwU81c+K3AZUn+km6N4cAaOzSGrao62HweBj5Fr6YujeUJWbahMPcPpPFW4MH5tl0KzcXHDwP7quqmvq92AZub5c3A7Utd25z5auzSWCaZSPLKZvmlwBuBh+nWOA6ssSvjWFXXVtWaqpqk9yiZf6iqn6dDYzhfjV0ZwzlJzmxuyiDJmcCPNzV1ZixPVKcec/FCJfk4cClwTpIZ4Hrg0iTr6c33HQDeNa76GpcA7wAeaOaaAa4DbgR2JrkaeBy4ajzlAfPX+PYOjeUqYEd6L2Q6BdhZVZ9J8iW6M47z1fiRDo3jIF36uzif3+3YGJ4HfKr3/1OcBnysqv4uyT10fywHWha3pEqSFseynT6SJJ04Q0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEmt/w9ydgs5SyHFgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['bmi'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2ff597c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['children'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e6970634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d2c3058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Column transformer\n",
    "\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), ['age', 'bmi', 'children']),\n",
    "    (OneHotEncoder(handle_unknown= 'ignore'), ['sex', 'smoker', 'region']))\n",
    "\n",
    "\n",
    "# Create X and Y\n",
    "X = insurance.drop('charges', axis = 1)\n",
    "y = insurance['charges']\n",
    "    \n",
    "    \n",
    "\n",
    "# build our train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# for the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "463c9bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2aa4c539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "20326b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65217391, 0.52905569, 0.8       , 0.        , 1.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "191123ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15217391, 0.27602906, 0.        , 0.        , 1.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "72278456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d5926cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "df77cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13342.6494 - mae: 13342.6494\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 998us/step - loss: 13333.4785 - mae: 13333.4785\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 851us/step - loss: 13312.0234 - mae: 13312.0234\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 13267.7930 - mae: 13267.7930\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 704us/step - loss: 13189.5830 - mae: 13189.5830\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 10767.5605 - mae: 10767.560 - 0s 763us/step - loss: 13066.4502 - mae: 13066.4502\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12888.1953 - mae: 12888.1953\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 880us/step - loss: 12644.6523 - mae: 12644.6523\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12325.5469 - mae: 12325.5469\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11925.9658 - mae: 11925.9658\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 11454.3350 - mae: 11454.3350\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 10949.8076 - mae: 10949.8076\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10448.9404 - mae: 10448.9404\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9951.6250 - mae: 9951.6250\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9482.7412 - mae: 9482.7412\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9066.7461 - mae: 9066.7461\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8721.9854 - mae: 8721.9854\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8441.2002 - mae: 8441.2002\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8227.5117 - mae: 8227.5117\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8081.9775 - mae: 8081.9775\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7973.8945 - mae: 7973.8945\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7899.1597 - mae: 7899.1597\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7840.3906 - mae: 7840.3906\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7787.9619 - mae: 7787.9619\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7749.2622 - mae: 7749.2622\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7697.9590 - mae: 7697.9590\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7656.0269 - mae: 7656.0269\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7613.4780 - mae: 7613.4780\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7570.9482 - mae: 7570.9482\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7527.4170 - mae: 7527.4170\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7483.5947 - mae: 7483.5947\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7439.4424 - mae: 7439.4424\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7395.0547 - mae: 7395.0547\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7346.8125 - mae: 7346.8125\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7300.0488 - mae: 7300.0488\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7249.8452 - mae: 7249.8452\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7199.5308 - mae: 7199.5308\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: 7148.4805 - mae: 7148.4805\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7093.6660 - mae: 7093.6660\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7038.1792 - mae: 7038.1792\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6981.7397 - mae: 6981.7397\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6922.7842 - mae: 6922.7847\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6860.1729 - mae: 6860.1729\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6793.7969 - mae: 6793.7969\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6726.6201 - mae: 6726.6201\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6657.4683 - mae: 6657.4683\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6586.3086 - mae: 6586.3086\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6507.5063 - mae: 6507.5063\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6428.6025 - mae: 6428.6025\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6342.7104 - mae: 6342.7104\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6258.0718 - mae: 6258.0718\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6164.7046 - mae: 6164.7046\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6068.6748 - mae: 6068.6748\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5970.0981 - mae: 5970.0981\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5862.5625 - mae: 5862.5625\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5753.9526 - mae: 5753.9526\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 821us/step - loss: 5638.0942 - mae: 5638.0942\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 733us/step - loss: 5519.8691 - mae: 5519.8691\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5401.3198 - mae: 5401.3198\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5277.3501 - mae: 5277.3501\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5149.7642 - mae: 5149.7642\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5019.3535 - mae: 5019.3535\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4889.6865 - mae: 4889.6865\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4756.8560 - mae: 4756.8560\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4629.4365 - mae: 4629.4365\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4503.5991 - mae: 4503.5991\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4392.9922 - mae: 4392.9922\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4284.3862 - mae: 4284.3862\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 4177.1299 - mae: 4177.129 - 0s 2ms/step - loss: 4182.6182 - mae: 4182.6182\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4089.5725 - mae: 4089.5725\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4003.3901 - mae: 4003.3901\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3929.0093 - mae: 3929.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3866.3110 - mae: 3866.3110\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3813.7144 - mae: 3813.7144\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3773.0312 - mae: 3773.0312\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3744.1995 - mae: 3744.1995\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3719.6870 - mae: 3719.6870\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3702.9109 - mae: 3702.9109\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3691.8792 - mae: 3691.8792\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3682.8350 - mae: 3682.8350\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3676.9766 - mae: 3676.9766\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3673.9492 - mae: 3673.9492\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3667.8452 - mae: 3667.8452\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3664.5757 - mae: 3664.5757\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3661.8562 - mae: 3661.8562\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3660.3047 - mae: 3660.3047\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3657.5134 - mae: 3657.5134\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 934us/step - loss: 3655.2202 - mae: 3655.2202\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3653.8831 - mae: 3653.8831\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 909us/step - loss: 3652.0193 - mae: 3652.0193\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3648.9990 - mae: 3648.9990\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3648.4458 - mae: 3648.4458\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3646.2300 - mae: 3646.2300\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3644.4377 - mae: 3644.4377\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3645.8774 - mae: 3645.8774\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3642.2576 - mae: 3642.2576\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3640.1187 - mae: 3640.1187\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 888us/step - loss: 3638.0647 - mae: 3638.0647\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3637.2051 - mae: 3637.2051\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3636.1707 - mae: 3636.1707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab131079a0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a NN model to fit on our normalized data\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 1.  create the model\n",
    "\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "insurance_model_4.compile(loss= tf.keras.losses.mae,\n",
    "                         optimizer= tf.keras.optimizers.Adam(),\n",
    "                         metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3  fit the model\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d44deb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 995us/step - loss: 3438.7844 - mae: 3438.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3438.784423828125, 3438.784423828125]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# evaluate the model 4 \n",
    "\n",
    "insurance_model_4.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4bf7ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/34 [..............................] - ETA: 0s - loss: 13158.0518 - mae: 13158.0518WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "34/34 [==============================] - 0s 968us/step - loss: 13342.6494 - mae: 13342.6494\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13333.4785 - mae: 13333.4785\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13312.0234 - mae: 13312.0234\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13267.7930 - mae: 13267.7930\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13189.5830 - mae: 13189.5830\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13066.4502 - mae: 13066.4502\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12888.1953 - mae: 12888.1953\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12644.6523 - mae: 12644.6523\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12325.5469 - mae: 12325.5469\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 11925.9658 - mae: 11925.9658\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 11454.3350 - mae: 11454.3350\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 10949.8076 - mae: 10949.8076\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 10448.9404 - mae: 10448.9404\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9951.6250 - mae: 9951.6250\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9482.7412 - mae: 9482.7412\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9066.7461 - mae: 9066.7461\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 8721.9854 - mae: 8721.9854\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8441.2002 - mae: 8441.2002\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 8227.5117 - mae: 8227.5117\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8081.9775 - mae: 8081.9775\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7973.8945 - mae: 7973.8945\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7899.1597 - mae: 7899.1597\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7840.3906 - mae: 7840.3906\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7787.9619 - mae: 7787.9619\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7749.2622 - mae: 7749.2622\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7697.9590 - mae: 7697.9590\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7656.0269 - mae: 7656.0269\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7613.4780 - mae: 7613.4780\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7570.9482 - mae: 7570.9482\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7527.4170 - mae: 7527.4170\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 7483.5947 - mae: 7483.5947\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7439.4424 - mae: 7439.4424\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 7395.0547 - mae: 7395.0547\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 7346.8125 - mae: 7346.8125\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7300.0488 - mae: 7300.0488\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7249.8452 - mae: 7249.8452\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7199.5308 - mae: 7199.5308\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7148.4805 - mae: 7148.4805\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7093.6660 - mae: 7093.6660\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7038.1792 - mae: 7038.1792\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6981.7397 - mae: 6981.7397\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6922.7842 - mae: 6922.7847\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6860.1729 - mae: 6860.1729\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6793.7969 - mae: 6793.7969\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 6726.6201 - mae: 6726.6201\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6657.4683 - mae: 6657.4683\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6586.3086 - mae: 6586.3086\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 929us/step - loss: 6507.5063 - mae: 6507.5063\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6428.6025 - mae: 6428.6025\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6342.7104 - mae: 6342.7104\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6258.0718 - mae: 6258.0718\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6164.7046 - mae: 6164.7046\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6068.6748 - mae: 6068.6748\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5970.0981 - mae: 5970.0981\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5862.5625 - mae: 5862.5625\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5753.9526 - mae: 5753.9526\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5638.0942 - mae: 5638.0942\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5519.8691 - mae: 5519.8691\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5401.3198 - mae: 5401.3198\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5277.3501 - mae: 5277.3501\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5149.7642 - mae: 5149.7642\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 5019.3535 - mae: 5019.3535\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4889.6865 - mae: 4889.6865\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4756.8560 - mae: 4756.8560\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4629.4365 - mae: 4629.4365\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4503.5991 - mae: 4503.5991\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4392.9922 - mae: 4392.9922\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 4284.3862 - mae: 4284.3862\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 4182.6182 - mae: 4182.6182\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4089.5725 - mae: 4089.5725\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4003.3901 - mae: 4003.3901\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3929.0093 - mae: 3929.0093\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3866.3110 - mae: 3866.3110\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3813.7144 - mae: 3813.7144\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.0312 - mae: 3773.0312\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3744.1995 - mae: 3744.1995\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3719.6870 - mae: 3719.6870\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3702.9109 - mae: 3702.9109\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3691.8792 - mae: 3691.8792\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3682.8350 - mae: 3682.8350\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3676.9766 - mae: 3676.9766\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3673.9492 - mae: 3673.9492\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3667.8452 - mae: 3667.8452\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3664.5757 - mae: 3664.5757\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3661.8562 - mae: 3661.8562\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3660.3047 - mae: 3660.3047\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3657.5134 - mae: 3657.5134\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3655.2202 - mae: 3655.2202\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3653.8831 - mae: 3653.8831\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3652.0193 - mae: 3652.0193\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3648.9990 - mae: 3648.9990\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3648.4458 - mae: 3648.4458\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3646.2300 - mae: 3646.2300\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3644.4377 - mae: 3644.4377\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3645.8774 - mae: 3645.8774\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3642.2576 - mae: 3642.2576\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3640.1187 - mae: 3640.1187\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3638.0647 - mae: 3638.0647\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3637.2051 - mae: 3637.2051\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3636.1707 - mae: 3636.1707\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3633.0803 - mae: 3633.0803\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3630.6155 - mae: 3630.6155\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3629.4307 - mae: 3629.4307\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3627.0291 - mae: 3627.0291\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3625.3789 - mae: 3625.3789\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3624.1887 - mae: 3624.1887\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3623.4666 - mae: 3623.4666\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3621.1238 - mae: 3621.1238\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3621.1895 - mae: 3621.1895\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3618.2805 - mae: 3618.2805\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3615.2791 - mae: 3615.2791\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3613.2454 - mae: 3613.2454\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3611.9092 - mae: 3611.9092\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3610.8167 - mae: 3610.8167\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3609.1033 - mae: 3609.1033\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3607.6526 - mae: 3607.6526\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3604.7563 - mae: 3604.7563\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3600.8140 - mae: 3600.8140\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3602.6384 - mae: 3602.6384\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3600.3203 - mae: 3600.3203\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 4277.8062 - mae: 4277.806 - 0s 909us/step - loss: 3595.2522 - mae: 3595.2522\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3594.6338 - mae: 3594.6338\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3592.6138 - mae: 3592.6138\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3590.3994 - mae: 3590.3994\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3588.4041 - mae: 3588.4041\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 733us/step - loss: 3587.5061 - mae: 3587.5061\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 3588.0410 - mae: 3588.0410\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 733us/step - loss: 3584.1001 - mae: 3584.1001\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3582.7319 - mae: 3582.7319\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3579.1135 - mae: 3579.1135\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3577.7139 - mae: 3577.7139\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3574.9951 - mae: 3574.9951\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3573.2947 - mae: 3573.2947\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3571.3865 - mae: 3571.3865\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 822us/step - loss: 3569.3606 - mae: 3569.3606\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 910us/step - loss: 3568.0547 - mae: 3568.0547\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3566.1060 - mae: 3566.1060\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 763us/step - loss: 3563.9617 - mae: 3563.9617\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 675us/step - loss: 3563.3352 - mae: 3563.3352\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3561.2300 - mae: 3561.2300\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3561.1250 - mae: 3561.1250\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3558.0391 - mae: 3558.0391\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3558.0339 - mae: 3558.0339\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3555.1953 - mae: 3555.1953\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 733us/step - loss: 3553.2446 - mae: 3553.2446\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3553.4753 - mae: 3553.4753\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3551.0718 - mae: 3551.0718\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3549.7549 - mae: 3549.7549\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3547.0066 - mae: 3547.0066\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 733us/step - loss: 3546.9907 - mae: 3546.9907\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3545.1938 - mae: 3545.1938\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3543.3826 - mae: 3543.3826\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3541.9124 - mae: 3541.9124\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3543.1577 - mae: 3543.1577\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3540.6169 - mae: 3540.6169\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3538.9231 - mae: 3538.9231\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 704us/step - loss: 3537.4109 - mae: 3537.4109\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3534.4917 - mae: 3534.4917\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3532.9485 - mae: 3532.9485\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3532.6982 - mae: 3532.6982\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3529.6243 - mae: 3529.6243\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3529.0967 - mae: 3529.0967\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 851us/step - loss: 3527.5425 - mae: 3527.5425\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3526.2844 - mae: 3526.2844\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 850us/step - loss: 3524.1594 - mae: 3524.1594\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3522.7070 - mae: 3522.7070\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3521.8069 - mae: 3521.8069\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3520.5654 - mae: 3520.5654\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3519.4631 - mae: 3519.4631\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 3518.0566 - mae: 3518.0566\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3517.6172 - mae: 3517.6172\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3516.0525 - mae: 3516.0525\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3514.9304 - mae: 3514.9304\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3513.6685 - mae: 3513.6685\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3512.3582 - mae: 3512.3582\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3512.1819 - mae: 3512.1819\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3512.5046 - mae: 3512.5046\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 880us/step - loss: 3510.2725 - mae: 3510.2725\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3512.1841 - mae: 3512.1841\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3507.1204 - mae: 3507.1204\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3505.0273 - mae: 3505.0273\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3504.4314 - mae: 3504.4314\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3502.5481 - mae: 3502.5481\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3501.8333 - mae: 3501.8333\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3501.4790 - mae: 3501.4790\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 909us/step - loss: 3498.9014 - mae: 3498.9014\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 939us/step - loss: 3499.2842 - mae: 3499.2842\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3496.6895 - mae: 3496.6895\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3495.1074 - mae: 3495.1074\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3496.6016 - mae: 3496.6016\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3502.1326 - mae: 3502.1326\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 997us/step - loss: 3491.8506 - mae: 3491.8506\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3491.6604 - mae: 3491.6604\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3488.8264 - mae: 3488.8264\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3488.7258 - mae: 3488.7258\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3489.5095 - mae: 3489.5095\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 821us/step - loss: 3485.7686 - mae: 3485.7686\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 792us/step - loss: 3484.7117 - mae: 3484.7117\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 968us/step - loss: 3483.4468 - mae: 3483.4468\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3484.3950 - mae: 3484.3950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab133d4e80>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a NN model to fit on our normalized data\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 1.  create the model\n",
    "\n",
    "insurance_model_5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 2. compile the model\n",
    "\n",
    "insurance_model_5.compile(loss= tf.keras.losses.mae,\n",
    "                         optimizer= tf.keras.optimizers.Adam(),\n",
    "                         metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3  fit the model\n",
    "insurance_model_5.fit(X_train_normal, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93712568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c43a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c560a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91602c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2bf128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
